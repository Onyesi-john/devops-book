<!DOCTYPE html>

<html lang="en">

<head>

<meta charset="UTF-8">

<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<meta name="generator" content="Asciidoctor 2.0.16">

<title>Part 3. How to Deploy Many Apps: Orchestration, VMs, Containers, and Serverless</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">

<style>

/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */

/* Uncomment the following line when using as a custom stylesheet */

/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */

html{font-family:sans-serif;-webkit-text-size-adjust:100%}

a{background:none}

a:focus{outline:thin dotted}

a:active,a:hover{outline:0}

h1{font-size:2em;margin:.67em 0}

b,strong{font-weight:bold}

abbr{font-size:.9em}

abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}

dfn{font-style:italic}

hr{height:0}

mark{background:#ff0;color:#000}

code,kbd,pre,samp{font-family:monospace;font-size:1em}

pre{white-space:pre-wrap}

q{quotes:"\201C" "\201D" "\2018" "\2019"}

small{font-size:80%}

sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}

sup{top:-.5em}

sub{bottom:-.25em}

img{border:0}

svg:not(:root){overflow:hidden}

figure{margin:0}

audio,video{display:inline-block}

audio:not([controls]){display:none;height:0}

fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}

legend{border:0;padding:0}

button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}

button,input{line-height:normal}

button,select{text-transform:none}

button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}

button[disabled],html input[disabled]{cursor:default}

input[type=checkbox],input[type=radio]{padding:0}

button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}

textarea{overflow:auto;vertical-align:top}

table{border-collapse:collapse;border-spacing:0}

*,::before,::after{box-sizing:border-box}

html,body{font-size:100%}

body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}

a:hover{cursor:pointer}

img,object,embed{max-width:100%;height:auto}

object,embed{height:100%}

img{-ms-interpolation-mode:bicubic}

.left{float:left!important}

.right{float:right!important}

.text-left{text-align:left!important}

.text-right{text-align:right!important}

.text-center{text-align:center!important}

.text-justify{text-align:justify!important}

.hide{display:none}

img,object,svg{display:inline-block;vertical-align:middle}

textarea{height:auto;min-height:50px}

select{width:100%}

.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}

div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}

a{color:#2156a5;text-decoration:underline;line-height:inherit}

a:hover,a:focus{color:#1d4b8f}

a img{border:0}

p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}

p aside{font-size:.875em;line-height:1.35;font-style:italic}

h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}

h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}

h1{font-size:2.125em}

h2{font-size:1.6875em}

h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}

h4,h5{font-size:1.125em}

h6{font-size:1em}

hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}

em,i{font-style:italic;line-height:inherit}

strong,b{font-weight:bold;line-height:inherit}

small{font-size:60%;line-height:inherit}

code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}

ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}

ul,ol{margin-left:1.5em}

ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}

ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}

ul.square{list-style-type:square}

ul.circle{list-style-type:circle}

ul.disc{list-style-type:disc}

ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}

dl dt{margin-bottom:.3125em;font-weight:bold}

dl dd{margin-bottom:1.25em}

blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}

blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}

@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}

h1{font-size:2.75em}

h2{font-size:2.3125em}

h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}

h4{font-size:1.4375em}}

table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}

table thead,table tfoot{background:#f7f8f7}

table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}

table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}

table tr.even,table tr.alt{background:#f8f8f7}

table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}

h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}

h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}

.center{margin-left:auto;margin-right:auto}

.stretch{width:100%}

.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}

.clearfix::after,.float-group::after{clear:both}

:not(pre).nobreak{word-wrap:normal}

:not(pre).nowrap{white-space:nowrap}

:not(pre).pre-wrap{white-space:pre-wrap}

:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}

pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}

pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}

pre>code{display:block}

pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}

em em{font-style:normal}

strong strong{font-weight:400}

.keyseq{color:rgba(51,51,51,.8)}

kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}

.keyseq kbd:first-child{margin-left:0}

.keyseq kbd:last-child{margin-right:0}

.menuseq,.menuref{color:#000}

.menuseq b:not(.caret),.menuref{font-weight:inherit}

.menuseq{word-spacing:-.02em}

.menuseq b.caret{font-size:1.25em;line-height:.8}

.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}

b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}

b.button::before{content:"[";padding:0 3px 0 2px}

b.button::after{content:"]";padding:0 2px 0 3px}

p a>code:hover{color:rgba(0,0,0,.9)}

#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}

#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}

#header::after,#content::after,#footnotes::after,#footer::after{clear:both}

#content{margin-top:1.25em}

#content::before{content:none}

#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}

#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}

#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}

#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}

#header .details span:first-child{margin-left:-.125em}

#header .details span.email a{color:rgba(0,0,0,.85)}

#header .details br{display:none}

#header .details br+span::before{content:"\00a0\2013\00a0"}

#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}

#header .details br+span#revremark::before{content:"\00a0|\00a0"}

#header #revnumber{text-transform:capitalize}

#header #revnumber::after{content:"\00a0"}

#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}

#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}

#toc>ul{margin-left:.125em}

#toc ul.sectlevel0>li>a{font-style:italic}

#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}

#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}

#toc li{line-height:1.3334;margin-top:.3334em}

#toc a{text-decoration:none}

#toc a:active{text-decoration:underline}

#toctitle{color:#7a2518;font-size:1.2em}

@media screen and (min-width:768px){#toctitle{font-size:1.375em}

body.toc2{padding-left:15em;padding-right:0}

#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}

#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}

#toc.toc2>ul{font-size:.9em;margin-bottom:0}

#toc.toc2 ul ul{margin-left:0;padding-left:1em}

#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}

body.toc2.toc-right{padding-left:0;padding-right:15em}

body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}

@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}

#toc.toc2{width:20em}

#toc.toc2 #toctitle{font-size:1.375em}

#toc.toc2>ul{font-size:.95em}

#toc.toc2 ul ul{padding-left:1.25em}

body.toc2.toc-right{padding-left:0;padding-right:20em}}

#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}

#content #toc>:first-child{margin-top:0}

#content #toc>:last-child{margin-bottom:0}

#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}

#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}

#content{margin-bottom:.625em}

.sect1{padding-bottom:.625em}

@media screen and (min-width:768px){#content{margin-bottom:1.25em}

.sect1{padding-bottom:1.25em}}

.sect1:last-child{padding-bottom:0}

.sect1+.sect1{border-top:1px solid #e7e7e9}

#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}

#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}

#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}

#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}

#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}

details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}

details{margin-left:1.25rem}

details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;-webkit-tap-highlight-color:transparent}

details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}

details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}

details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}

.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}

table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}

.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}

.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}

.admonitionblock>table td.icon{text-align:center;width:80px}

.admonitionblock>table td.icon img{max-width:none}

.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}

.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}

.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}

.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}

.exampleblock>.content>:first-child{margin-top:0}

.exampleblock>.content>:last-child{margin-bottom:0}

.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}

.sidebarblock>:first-child{margin-top:0}

.sidebarblock>:last-child{margin-bottom:0}

.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}

.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}

.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}

@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}

@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}

.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}

.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}

.listingblock>.content{position:relative}

.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}

.listingblock:hover code[data-lang]::before{display:block}

.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}

.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}

.listingblock pre.highlightjs{padding:0}

.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}

.listingblock pre.prettyprint{border-width:0}

.prettyprint{background:#f7f7f8}

pre.prettyprint .linenums{line-height:1.45;margin-left:2em}

pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}

pre.prettyprint li code[data-lang]::before{opacity:1}

pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}

table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}

table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}

table.linenotable td.code{padding-left:.75em}

table.linenotable td.linenos{border-right:1px solid;opacity:.35;padding-right:.5em}

pre.pygments .lineno{border-right:1px solid;opacity:.35;display:inline-block;margin-right:.75em}

pre.pygments .lineno::before{content:"";margin-right:-.125em}

.quoteblock{margin:0 1em 1.25em 1.5em;display:table}

.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}

.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}

.quoteblock blockquote{margin:0;padding:0;border:0}

.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}

.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}

.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}

.verseblock{margin:0 1em 1.25em}

.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}

.verseblock pre strong{font-weight:400}

.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}

.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}

.quoteblock .attribution br,.verseblock .attribution br{display:none}

.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}

.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}

.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}

.quoteblock.abstract{margin:0 1em 1.25em;display:block}

.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}

.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}

.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}

.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}

.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}

p.tableblock:last-child{margin-bottom:0}

td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}

td.tableblock>.content>:last-child{margin-bottom:-1.25em}

table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}

table.grid-all>*>tr>*{border-width:1px}

table.grid-cols>*>tr>*{border-width:0 1px}

table.grid-rows>*>tr>*{border-width:1px 0}

table.frame-all{border-width:1px}

table.frame-ends{border-width:1px 0}

table.frame-sides{border-width:0 1px}

table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}

table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}

table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}

table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}

table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}

th.halign-left,td.halign-left{text-align:left}

th.halign-right,td.halign-right{text-align:right}

th.halign-center,td.halign-center{text-align:center}

th.valign-top,td.valign-top{vertical-align:top}

th.valign-bottom,td.valign-bottom{vertical-align:bottom}

th.valign-middle,td.valign-middle{vertical-align:middle}

table thead th,table tfoot th{font-weight:bold}

tbody tr th{background:#f7f8f7}

tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}

p.tableblock>code:only-child{background:none;padding:0}

p.tableblock{font-size:1em}

ol{margin-left:1.75em}

ul li ol{margin-left:1.5em}

dl dd{margin-left:1.125em}

dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}

ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}

ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}

ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}

ul.unstyled,ol.unstyled{margin-left:0}

ul.checklist>li>p:first-child{margin-left:-1em}

ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}

ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}

ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}

ul.inline>li{margin-left:1.25em}

.unstyled dl dt{font-weight:400;font-style:normal}

ol.arabic{list-style-type:decimal}

ol.decimal{list-style-type:decimal-leading-zero}

ol.loweralpha{list-style-type:lower-alpha}

ol.upperalpha{list-style-type:upper-alpha}

ol.lowerroman{list-style-type:lower-roman}

ol.upperroman{list-style-type:upper-roman}

ol.lowergreek{list-style-type:lower-greek}

.hdlist>table,.colist>table{border:0;background:none}

.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}

td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}

td.hdlist1{font-weight:bold;padding-bottom:1.25em}

td.hdlist2{word-wrap:anywhere}

.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}

.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}

.colist td:not([class]):first-child img{max-width:none}

.colist td:not([class]):last-child{padding:.25em 0}

.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}

.imageblock.left{margin:.25em .625em 1.25em 0}

.imageblock.right{margin:.25em 0 1.25em .625em}

.imageblock>.title{margin-bottom:0}

.imageblock.thumb,.imageblock.th{border-width:6px}

.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}

.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}

.image.left{margin-right:.625em}

.image.right{margin-left:.625em}

a.image{text-decoration:none;display:inline-block}

a.image object{pointer-events:none}

sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}

sup.footnote a,sup.footnoteref a{text-decoration:none}

sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}

#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}

#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}

#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}

#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}

#footnotes .footnote:last-of-type{margin-bottom:0}

#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}

.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}

.gist .file-data>table td.line-data{width:99%}

div.unbreakable{page-break-inside:avoid}

.big{font-size:larger}

.small{font-size:smaller}

.underline{text-decoration:underline}

.overline{text-decoration:overline}

.line-through{text-decoration:line-through}

.aqua{color:#00bfbf}

.aqua-background{background:#00fafa}

.black{color:#000}

.black-background{background:#000}

.blue{color:#0000bf}

.blue-background{background:#0000fa}

.fuchsia{color:#bf00bf}

.fuchsia-background{background:#fa00fa}

.gray{color:#606060}

.gray-background{background:#7d7d7d}

.green{color:#006000}

.green-background{background:#007d00}

.lime{color:#00bf00}

.lime-background{background:#00fa00}

.maroon{color:#600000}

.maroon-background{background:#7d0000}

.navy{color:#000060}

.navy-background{background:#00007d}

.olive{color:#606000}

.olive-background{background:#7d7d00}

.purple{color:#600060}

.purple-background{background:#7d007d}

.red{color:#bf0000}

.red-background{background:#fa0000}

.silver{color:#909090}

.silver-background{background:#bcbcbc}

.teal{color:#006060}

.teal-background{background:#007d7d}

.white{color:#bfbfbf}

.white-background{background:#fafafa}

.yellow{color:#bfbf00}

.yellow-background{background:#fafa00}

span.icon>.fa{cursor:default}

a span.icon>.fa{cursor:inherit}

.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}

.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}

.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}

.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}

.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}

.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}

.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}

.conum[data-value] *{color:#fff!important}

.conum[data-value]+b{display:none}

.conum[data-value]::after{content:attr(data-value)}

pre .conum[data-value]{position:relative;top:-.125em}

b.conum *{color:inherit!important}

.conum:not([data-value]):empty{display:none}

dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}

h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}

p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}

p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}

p{margin-bottom:1.25rem}

.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}

.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}

.print-only{display:none!important}

@page{margin:1.25cm .75cm}

@media print{*{box-shadow:none!important;text-shadow:none!important}

html{font-size:80%}

a{color:inherit!important;text-decoration:underline!important}

a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}

a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}

abbr[title]{border-bottom:1px dotted}

abbr[title]::after{content:" (" attr(title) ")"}

pre,blockquote,tr,img,object,svg{page-break-inside:avoid}

thead{display:table-header-group}

svg{max-width:100%}

p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}

h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}

#header,#content,#footnotes,#footer{max-width:none}

#toc,.sidebarblock,.exampleblock>.content{background:none!important}

#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}

body.book #header{text-align:center}

body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}

body.book #header .details{border:0!important;display:block;padding:0!important}

body.book #header .details span:first-child{margin-left:0!important}

body.book #header .details br{display:block}

body.book #header .details br+span::before{content:none!important}

body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}

body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}

.listingblock code[data-lang]::before{display:block}

#footer{padding:0 .9375em}

.hide-on-print{display:none!important}

.print-only{display:block!important}

.hide-for-print{display:none!important}

.show-for-print{display:inherit!important}}

@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}

.sect1{padding:0!important}

.sect1+.sect1{border:0}

#footer{background:none}

#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}

@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}

</style>


<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">

<style>
h1 {
    margin-bottom: 50px;
}
h2 {
    margin-top: 50px;
    margin-bottom: 10px;
}
h3 {
    margin-top: 30px;
    margin-bottom: 10px;
}
h4 {
    margin-top: 20px;
    margin-bottom: 10px;
}

pre {
    line-height: 12px !important;
    font-size: 14px !important;
    margin-bottom: 0 !important;
}

#toc-dynamic>ul {
    margin: 0;
}

table ul {
    margin-left: 0;
    padding-left: 15px;
}
</style>

</head>

<body class="book" data-bs-spy="scroll" data-bs-target="#toc-dynamic" data-bs-smooth-scroll="true" tabindex="0">

<div class="container">
  <div class="row">
    <div class="col-sm-4">
      <nav id="toc-dynamic" class="sticky-top vh-100" style="overflow: scroll; padding-top: 25px; padding-bottom: 25px;">
          <a href="index.html" class="h6 text-decoration-none">Fundamentals of DevOps and Software Delivery</a>
          <ul class="nav nav-pills flex-column"><li class="nav-item"><a href="#how_to_deploy_many_apps" class="nav-link">3. How to Deploy Many Apps: Orchestration, VMs, Containers, and Serverless</a>
</li>

<li class="nav-item"><a href="#introduction_to_orchestration" class="nav-link">3.1. An introduction to orchestration</a></li>

<li class="nav-item"><a href="#_server_orchestration" class="nav-link">3.2. Server orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#example_server_orchestration_ansible" class="nav-link">3.2.1. Example: server orchestration using Ansible</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#_example_deploying_multiple_servers_in_aws_using_ansible" class="nav-link">Example: deploying multiple servers in AWS using Ansible</a></li>

<li class="nav-item"><a href="#example_better_security_and_process_supervisors" class="nav-link">Example: app security and reliability with OS users and process supervisors</a></li>

<li class="nav-item"><a href="#example_ansible_load_balancing" class="nav-link">Example: load balancing using Ansible and Nginx</a></li>

<li class="nav-item"><a href="#example_ansible_rolling_updates" class="nav-link">Example: rolling out updates with Ansible</a></li>

</ul>

</li>

</ul>

</li>

<li class="nav-item"><a href="#_vm_orchestration" class="nav-link">3.3. VM orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#example_vm_orchestration" class="nav-link">3.3.1. Example: VM orchestration using Packer, OpenTofu, and AWS Auto Scaling Groups</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#_example_building_vm_images_using_packer" class="nav-link">Example: building VM images using Packer</a></li>

<li class="nav-item"><a href="#_example_deploying_vm_images_in_aws_using_opentofu_and_auto_scaling_groups" class="nav-link">Example: deploying VM images in AWS using OpenTofu and Auto Scaling Groups</a></li>

<li class="nav-item"><a href="#example_aws_load_balancing" class="nav-link">Example: load balancing using OpenTofu and AWS</a></li>

<li class="nav-item"><a href="#example_aws_automatic_rollouts" class="nav-link">Example: rolling out updates with OpenTofu and Auto Scaling Groups</a></li>

</ul>

</li>

</ul>

</li>

<li class="nav-item"><a href="#_container_orchestration" class="nav-link">3.4. Container orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#_an_example_of_container_orchestration" class="nav-link">3.4.1. An example of container orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#example_docker_crash_course" class="nav-link">Example: a crash course on Docker</a></li>

<li class="nav-item"><a href="#example_kubernetes" class="nav-link">Example: a crash course on Kubernetes</a></li>

<li class="nav-item"><a href="#_example_load_balancing_with_kubernetes" class="nav-link">Example: load balancing with Kubernetes</a></li>

<li class="nav-item"><a href="#_example_rolling_out_updates_with_kubernetes" class="nav-link">Example: rolling out updates with Kubernetes</a></li>

<li class="nav-item"><a href="#example_docker_kubernetes_aws" class="nav-link">Example: deploying a Kubernetes cluster in AWS</a></li>

<li class="nav-item"><a href="#_example_pushing_docker_images_to_ecr" class="nav-link">Example: pushing Docker images to ECR</a></li>

<li class="nav-item"><a href="#_example_deploying_apps_into_eks" class="nav-link">Example: deploying apps into EKS</a></li>

</ul>

</li>

</ul>

</li>

<li class="nav-item"><a href="#_serverless_orchestration" class="nav-link">3.5. Serverless orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#example_serverless" class="nav-link">3.5.1. An example of serverless orchestration</a>

<ul class="nav nav-pills flex-column">

<li class="nav-item"><a href="#_example_serverless_functions_with_aws_lambda" class="nav-link">Example: serverless functions with AWS Lambda</a></li>

<li class="nav-item"><a href="#_example_triggering_lambda_functions_with_http_requests_using_api_gateway" class="nav-link">Example: triggering Lambda functions with HTTP requests using API Gateway</a></li>

<li class="nav-item"><a href="#_example_rolling_out_updates_with_lambda" class="nav-link">Example: rolling out updates with Lambda</a></li>

</ul>

</li>

</ul>

</li>

<li class="nav-item"><a href="#comparison_orchestration_options" class="nav-link">3.6. Comparison of orchestration options</a></li>

<li class="nav-item"><a href="#_conclusion_3" class="nav-link">3.7. Conclusion</a></li>

</ul>

      </nav>
    </div>
    <div class="col-sm-8">

<div id="content">
<div class="sect1">

<h1 id="how_to_deploy_many_apps">Part 3. How to Deploy Many Apps: Orchestration, VMs, Containers, and Serverless</h1>

<div class="sectionbody">

<div class="paragraph">

<p>In <a href="02.html#how_to_deploy_your_app">Part 1</a> and <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>, you deployed an app on a single server. This

is a great way to learn and to get started, and for smaller and simpler apps, a single server may be all you ever need.

However, for many production use cases, where you&#8217;re building a business that depends on that app, you may run into the

following problems with just a single server:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Outages due to hardware issues</dt>

<dd>

<p>If the server has a hardware problem, such as the power supply dying, your users will experience an outage until you

replace the server.</p>

</dd>

<dt class="hdlist1">Outages due to software issues</dt>

<dd>

<p>If the app crashes due to a software problem, such as a bug in the code, your users will experience an outage until

you manually restart it.</p>

</dd>

<dt class="hdlist1">Outages due to load</dt>

<dd>

<p>If your app becomes popular enough, the load may exceed what a single server can handle, and

your users will experience degraded performance, and potentially outages as well.</p>

</dd>

<dt class="hdlist1">Outages due to deployments</dt>

<dd>

<p>If you want to roll out a new version of your app, it&#8217;s hard to do so with just a

single server without at least a brief outage while you shut down the old version and replace it with the new version.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>In short, a single copy of your app is a <em>single point of failure</em>. To run applications in production, you typically want

multiple copies, called <em>replicas</em>, of your app. Moreover, you also want a way to manage those replicas: something that

can automatically handle hardware issues, software issues, load issues, deployments, and so on. Although you could

build your own solutions for deploying and managing replicas, it&#8217;s a tremendous amount of work, and there are tools out

there that do it for you: these are called <em>orchestration tools</em>.</p>

</div>

<div class="paragraph">

<p>If you search around, you&#8217;ll quickly find that there are many orchestration tools out there, including Kubernetes,

EKS, GKE, AKS, OpenShift, EC2, ECS, Marathon/Mesos, Nomad, AWS Lambda, Google Cloud Functions, Azure Serverless,

Capistrano, Ansible, and many others. It seems like there&#8217;s a new, hot orchestration tool nearly every day. How do you

keep track of them all? Which one should you use? How do these tools compare?</p>

</div>

<div class="paragraph">

<p>This Part will help you navigate the orchestration space by introducing you to the most common

types of orchestration tools, which, broadly speaking, fall into the following four categories:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Server orchestration: e.g., use Ansible to deploy code onto a cluster of servers.</p>

</li>

<li>

<p>VM orchestration: e.g., deploy VMs into an Auto Scaling Group.</p>

</li>

<li>

<p>Container orchestration: e.g., deploy containers into a Kubernetes cluster.</p>

</li>

<li>

<p>Serverless orchestration: e.g., deploy functions using AWS Lambda.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>You&#8217;ll work through examples where you deploy the same app using each of these approaches. which will let you see how

different orchestration approaches perform across a variety of dimensions (e.g., rolling out updates, load balancing,

auto scaling, auto healing, and so on), so that you can pick the right tool for the job.</p>

</div>

<div class="paragraph">

<p>Here&#8217;s an outline of this post:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>An introduction to orchestration</p>

</li>

<li>

<p>Server orchestration</p>

</li>

<li>

<p>VM orchestration</p>

</li>

<li>

<p>Container orchestration</p>

</li>

<li>

<p>Serverless orchestration</p>

</li>

<li>

<p>Comparison of orchestration options</p>

</li>

</ul>

</div>

<div class="sect2">

<h2 id="introduction_to_orchestration">An introduction to orchestration</h2>

<div class="paragraph">

<p>In the world of classical music, a conductor is responsible for orchestration: that is, they direct the orchestra,

coordinating all the individual members to start or stop playing, to increase or decrease the tempo, to play quieter or

louder, and so on. In the world of software, an <em>orchestration tool</em> is responsible for orchestration: they direct

software clusters, coordinating all the individual apps to start or stop, to increase or decreases the hardware

resources available to them, to increase or decrease the number of replicas, and so on.</p>

</div>

<div class="paragraph">

<p>These days, for many people, the term "orchestration" is associated with Kubernetes, but the underlying needs

have been around since the first programmer ran the first app for others to use. Anyone running an app in production

needs to solve most or all of the following <em>core orchestration problems</em>:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Deployment</dt>

<dd>

<p>You need a way to initially deploy one or more replicas of your app onto your servers. After the initial deployment,

you need a way to periodically roll out updates to all replicas of your app, and in most cases, you want a way to

roll out those updates without your users experiencing downtime (known as a <em>zero-downtime deployment</em>).</p>

</dd>

<dt class="hdlist1">Scheduling</dt>

<dd>

<p>For each deployment, you need to decide which apps should run on which servers, ensuring that each app gets the

resources (CPU, memory, disk space) it needs. This is known as <em>scheduling</em>. With some orchestration tools, you do

the scheduling yourself, manually; other orchestration tools provide a <em>scheduler</em> that can do it automatically,

and this scheduler usually implements some sort of <em>bin packing algorithm</em> to try to use the resources available as

efficiently as possible.</p>

</dd>

<dt class="hdlist1">Rollback</dt>

<dd>

<p>Sometimes, if there is a problem when rolling out an update, you need a way to roll back all replicas to a previous

version.</p>

</dd>

<dt class="hdlist1">Auto scaling</dt>

<dd>

<p>As load goes up and down, you need a way to automatically scale your app up and down in response. This may include

<em>vertical scaling</em>, where you scale the resources available to your existing servers up or down, such as getting

faster CPUs, more memory, or bigger hard drives, as well as <em>horizontal scaling</em>, where you deploy more servers and/or

more replicas of your app across your servers.</p>

</dd>

<dt class="hdlist1">Auto healing</dt>

<dd>

<p>You need something to monitor your apps, detect if they are not healthy (i.e., the app is not responding correctly or

at all), and to automatically respond to problems by restarting or replacing the app or server.</p>

</dd>

<dt class="hdlist1">Configuration</dt>

<dd>

<p>If you have multiple environments (e.g., dev, stage, and prod), you need a way to be able to configure the app

differently in each environment: e.g., use different domain names or different memory settings in each environment.</p>

</dd>

<dt class="hdlist1">Secrets management</dt>

<dd>

<p>You may need a way to securely pass sensitive configuration data to your apps (e.g., passwords, API keys).</p>

</dd>

<dt class="hdlist1">Load balancing</dt>

<dd>

<p>If you are running multiple replicas of your app, you may need a way to distribute traffic across all those replicas.</p>

</dd>

<dt class="hdlist1">Service communication</dt>

<dd>

<p>If you are running multiple apps, you may need to give them a way to communicate with each other, including a way to

find out how to connect to other apps (<em>service discovery</em>), and ways to control and monitor that communication,

including authentication, authorization, encryption, error handling, observability, and so on (<em>service mesh</em>).</p>

</dd>

<dt class="hdlist1">Disk management</dt>

<dd>

<p>If your app stores data on a local hard drive, then as you deploy replicas of your app to various servers, you need

to find a way to ensure that the right hard drive is connected to the right servers.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>Over the years, there have been dozens of different approaches to solving each of these problems. In the pre-cloud era,

since every on-prem deployment was different, most companies wrote their own bespoke solutions, typically consisting of

gluing together various scripts and tools to solve each problem. Nowadays, the industry is starting to standardize

around four broad types of solutions:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Server orchestration</dt>

<dd>

<p>You have a pool of servers that you manage.</p>

</dd>

<dt class="hdlist1">VM orchestration</dt>

<dd>

<p>Instead of managing servers directly, you manage VM images.</p>

</dd>

<dt class="hdlist1">Container orchestration</dt>

<dd>

<p>Instead of managing servers directly, you manage containers.</p>

</dd>

<dt class="hdlist1">Serverless orchestration</dt>

<dd>

<p>You no longer think about servers at all, and just focus on managing apps, or even

individual functions.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>We&#8217;ll discuss each of these in turn in the next several sections, starting with server orchestration.</p>

</div>

</div>

<div class="sect2">

<h2 id="_server_orchestration">Server orchestration</h2>

<div class="paragraph">

<p>The original approach used in the pre-cloud era, and one that, for better or worse, is still fairly common today, is to

do the following:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Set up a bunch of servers.</p>

</li>

<li>

<p>Deploy your apps across the servers.</p>

</li>

<li>

<p>When you need to roll out changes, update the servers in place.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>I&#8217;ve seen companies use a variety of tools for implementing this approach, including configuration management

tools (e.g., Ansible, Chef, Puppet), specialized deployment scripts (e.g., <a href="https://capistranorb.com/">Capistrano</a>,

<a href="https://deployer.org/">Deployer</a>, <a href="http://nadarei.co/mina/">Mina</a>, <a href="https://www.fabfile.org/">Fabric</a>,

<a href="https://github.com/shipitjs/shipit">Shipit</a>), and, perhaps the most common approach, thousands and thousands of

ad hoc scripts.</p>

</div>

<div class="paragraph">

<p>Because this approach pre-dates the cloud era, it also predates most attempts at creating standardized tooling for it

(which is why there are so many different tools for it), and I&#8217;m not aware of any single, commonly accepted name for it.

Most people would just refer to it as "deployment tooling," as deployment was the primary focus (as opposed to auto

scaling, auto healing, service discovery, etc.). For the purposes of this blog post series, I&#8217;ll refer to it as <em>server

orchestration</em>, to disambiguate it from the newer orchestration approaches you&#8217;ll see later, such as VM and

container orchestration.</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Key takeaway #1</div>

<div class="paragraph">

<p>Server orchestration is an older, mutable infrastructure approach where you have a fixed set of servers that you

maintain and update in place.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="sect3">

<h3 id="example_server_orchestration_ansible">Example: server orchestration using Ansible</h3>

<div class="paragraph">

<p>To get a feel for server orchestration, let&#8217;s use Ansible. In <a href="03.html#example_deploy_ec2_using_ansible">Section 2.3.2.1</a>, you saw how to

deploy a single EC2 instance using Ansible. In this post, you&#8217;ll first use Ansible to deploy

multiple EC2 instances, and once you have several servers to work with, you&#8217;ll be able to see what server orchestration

looks like in practice.</p>

</div>

<div class="sect4">

<h4 id="_example_deploying_multiple_servers_in_aws_using_ansible">Example: deploying multiple servers in AWS using Ansible</h4>

<div class="admonitionblock note">

<table>

<tr>

<td class="icon">

<div class="title">Note</div>

</td>

<td class="content">

<div class="title">Example Code</div>

<div class="paragraph">

<p>As a reminder, you can find all the code examples in the blog post series&#8217;s <a href="https://github.com/brikis98/fundamentals-of-devops-code">sample

code repo in GitHub</a>.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>The first thing you need for server orchestration is a bunch of servers. If you have existing servers you

can use—e.g., several physical servers on-prem or several virtual servers in the cloud—and you have SSH access to those

servers, you can skip this section, and go to the next one.</p>

</div>

<div class="paragraph">

<p>If you don&#8217;t have servers you can use, this section will show you how to deploy several EC2 instances using Ansible.

As mentioned in <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>, deploying and managing servers (hardware) is not really what

configuration management tools were designed to do, but for learning and testing, Ansible is good enough. Note that

the way you&#8217;ll use Ansible to deploy multiple EC2 instances in this section is meant to showcase server orchestration in

its canonical form, with a fixed set of servers, and <em>not</em> the idiomatic approach for running multiple servers in the

cloud; you&#8217;ll see the more idiomatic approach later in this blog post, in the VM orchestration section.</p>

</div>

<div class="paragraph">

<p>Head into the <em>fundamentals-of-devops</em> folder you created in <a href="02.html#how_to_deploy_your_app">Part 1</a> to work through the

examples in this blog post series, and create a new subfolder for this blog post and the Ansible

playbook:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/ansible

$ cd ch3/ansible</pre>

</div>

</div>

<div class="paragraph">

<p>Inside the <em>ansible</em> folder, create a new playbook called <em>create_ec2_instances_playbook.yml</em> (note the "s" in

"instances," implying multiple instances, unlike the playbook from <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>), with the

contents shown in <a href="04.html#example_ansible_ec2_instances_variables">Example 26</a>:</p>

</div>

<div id="example_ansible_ec2_instances_variables" class="exampleblock">

<div class="title">Example 26. Ansible playbook to create multiple EC2 instances (<em>ch3/ansible/create_ec2_instances_playbook.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Deploy EC2 instances in AWS</span></span>

  <span style="color:#606">hosts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">localhost</span></span>

  <span style="color:#606">gather_facts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">no</span></span>

  <span style="color:#606">environment</span>:

    <span style="color:#606">AWS_REGION</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">us-east-2</span></span>

  <span style="color:#606">vars_prompt</span>:                                                # <b class="conum">(1)</b>

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: num_instances</span></span>

      <span style="color:#606">prompt</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">How many instances to create?</span></span>

      <span style="color:#606">private</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">false</span></span>

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: base_name</span></span>

      <span style="color:#606">prompt</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">What to use as the base name for resources?</span></span>

      <span style="color:#606">private</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">false</span></span>

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: http_port</span></span>

      <span style="color:#606">prompt</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">What port to use for HTTP requests?</span></span>

      <span style="color:#606">private</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">false</span></span>

  <span style="color:#606">tasks</span>:

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Create security group</span></span>

      <span style="color:#606">amazon.aws.ec2_security_group</span>:

        <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ base_name }}</span><span style="color:#710">&quot;</span></span>

        <span style="color:#606">description</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ base_name }}</span><span style="color:#710">&quot;</span></span>

        <span style="color:#606">rules</span>:

          - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">proto: tcp</span></span>

            <span style="color:#606">ports</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">[&quot;{{ http_port }}&quot;]</span></span>

            <span style="color:#606">cidr_ip</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">0.0.0.0/0</span></span>

          - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">proto: tcp</span></span>

            <span style="color:#606">ports</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">[22]</span></span>

            <span style="color:#606">cidr_ip</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">0.0.0.0/0</span></span>

      <span style="color:#606">register</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">aws_security_group</span></span>



    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Create a new EC2 key pair</span></span>

      <span style="color:#606">amazon.aws.ec2_key</span>:

        <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ansible-ch3                                     </span></span># <b class="conum">(2)</b>

        <span style="color:#606">file_name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ansible-ch3.key</span></span>

      <span style="color:#606">no_log</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

      <span style="color:#606">register</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">aws_ec2_key_pair</span></span>



    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Create EC2 instances with Amazon Linux 2003 AMI</span></span>

      <span style="color:#606">loop</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ range(num_instances | int) | list }}</span><span style="color:#710">&quot;</span></span>         # <b class="conum">(3)</b>

      <span style="color:#606">amazon.aws.ec2_instance</span>:

        <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ '%s-%d' | format(base_name, item) }}</span><span style="color:#710">&quot;</span></span>       # <b class="conum">(4)</b>

        <span style="color:#606">key_name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ aws_ec2_key_pair.key.name }}</span><span style="color:#710">&quot;</span></span>

        <span style="color:#606">instance_type</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">t2.micro</span></span>

        <span style="color:#606">security_group</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ aws_security_group.group_id }}</span><span style="color:#710">&quot;</span></span>

        <span style="color:#606">image_id</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ami-0900fe555666598a2</span></span>

        <span style="color:#606">tags</span>:

          <span style="color:#606">Ansible</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">{{ base_name }}</span><span style="color:#710">&quot;</span></span>                          # <b class="conum">(5)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This is similar to the Ansible Playbook you saw in <a href="03.html#example_deploy_ec2_using_ansible">Section 2.3.2.1</a>, which deployed a

single EC2 instance, except for the following changes to allow deploying multiple instances:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>In order to make this playbook reusable for creating instances for a variety of use cases, it uses <code>vars_prompt</code> to

prompt you for several input variables: <code>num_instances</code>, which is how many EC2 instances to create; <code>base_name</code>,

which will be used to name all the resources created by this playbook; <code>http_port</code>, which is the port the instance

should listen on for HTTP requests.</p>

</li>

<li>

<p>This playbook uses a new name for the EC2 key pair to ensure it doesn&#8217;t conflict with key pairs from other

posts.</p>

</li>

<li>

<p>This playbook uses the <code>loop</code> keyword to create multiple EC2 instances. <code>loop</code> takes in a list and loops over

the items in that list, just like a <code>for</code>-loop in a general purpose programming language. The list this code passes

to <code>loop</code> is generated by the <code>range(N)</code> function, which returns the integers from 0 to <code>N</code>. In this case, <code>N</code> is

set to <code>num_instances</code>, which is one of the variables this playbook will prompt you for.</p>

</li>

<li>

<p>As the <code>loop</code> keyword iterates through each item in the list, it makes that item available to your code under the

<code>item</code> keyword. Since the list just contains integers generated by the <code>range</code> function, that means <code>item</code> will be

set to the digits 0, 1, 2, and so on. The code uses the <code>format</code> function to give each EC2 instance a unique name

that includes the <code>base_name</code> and followed by the digit in <code>item</code>: so if you enter <code>sample_app_instances</code> as the

<code>base_name</code>, the instances will be named <code>sample_app_instances_0</code>, <code>sample_app_instances_1</code>,

<code>sample_app_instances_2</code>, and so on.</p>

</li>

<li>

<p>Set the <code>Ansible</code> tag on each instance to the value of <code>base_name</code>. You will use this in the next section.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>To run this playbook, make sure Ansible is installed, authenticate to AWS as described in

<a href="03.html#example_authenticate_on_the_cli">Section 2.2</a>, and run <code>ansible-playbook</code> as before. Ansible will start to interactively prompt

you for the variables in <code>vars_prompt</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v create_ec2_instances_playbook.yml

How many instances to create?: 3

What to use as the base name for resources?: sample_app_instances

What port to use for HTTP requests?: 8080</pre>

</div>

</div>

<div class="paragraph">

<p>You can enter the values interactively and hit Enter, or, alternatively, you can define the variables in a YAML file,

such as the <em>sample-app-vars.yml</em> file shown in <a href="04.html#example_ansible_sample_app_variables_file">Example 27</a>:</p>

</div>

<div id="example_ansible_sample_app_variables_file" class="exampleblock">

<div class="title">Example 27. Variables file to create EC2 instances for the sample app (<em>ch3/ansible/sample-app-vars.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">num_instances</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">3</span></span>

<span style="color:#606">base_name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample_app_instances</span></span>

<span style="color:#606">http_port</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">8080</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>You can then use the <code>--extra-vars</code> flag to pass this variables file to the <code>ansible-playbook</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v create_ec2_instances_playbook.yml --extra-vars "@sample-app-vars.yml"</pre>

</div>

</div>

<div class="paragraph">

<p>This will create three empty servers that you can configure and manage as you wish. It&#8217;s a great playground to get a

sense for server orchestration. As a first step, let&#8217;s improve the security and reliability of your app deployments, as

discussed next.</p>

</div>

</div>

<div class="sect4">

<h4 id="example_better_security_and_process_supervisors">Example: app security and reliability with OS users and process supervisors</h4>

<div class="paragraph">

<p>As explained in <a href="02.html#simplified_example_not_for_prod">These are simplified examples for learning, not for production (watch out for snakes!)</a>, the code used in the previous blog posts had a

number of concerns related to security and reliability issues: e.g., running the app as a root user, listening on port

80, no automatic app restart in case of crashes, and so on. It&#8217;s time to fix these issues and get this code a bit

closer to something you could use in production.</p>

</div>

<div class="paragraph">

<p>First, just as in <a href="03.html#example_configure_server_ansible">Section 2.3.2.2</a>, you need to tell Ansible what servers you want to configure.

You do this using either an inventory file or, if you deployed servers in the cloud, such as the EC2 instances in the

previous section, you can use an inventory plugin, as shown in <a href="04.html#example_ansible_inventory_plugin_multiple_servers">Example 28</a>,

to discover your servers automatically.</p>

</div>

<div id="example_ansible_inventory_plugin_multiple_servers" class="exampleblock">

<div class="title">Example 28. Inventory plugin to discover EC2 instances automatically (<em>ch3/ansible/inventory.aws_ec2.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">plugin</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">amazon.aws.aws_ec2</span></span>

<span style="color:#606">regions</span>:

  - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">us-east-2</span></span>

<span style="color:#606">keyed_groups</span>:

  - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">key: tags.Ansible</span></span>

<span style="color:#606">leading_separator</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">''</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Just as in the previous blog post, this inventory file will create groups based on the <code>Ansible</code> tag.

If you used the playbook in the previous section, that tag will be set to the value you entered for the <code>base_name</code>

variable. In the preceding section, I used "sample_app_instances" as the <code>base_name</code>, so that&#8217;s what the group will be

called. You&#8217;ll need to configure group variables for this group by creating a YAML file with the name of the group in

the <em>group_vars</em> folder. So that will be <em>group_vars/sample_app_instances.yml</em>, as shown in

<a href="04.html#example_ansible_group_vars_multiple_servers">Example 29</a>:</p>

</div>

<div id="example_ansible_group_vars_multiple_servers" class="exampleblock">

<div class="title">Example 29. Configure group variables for your sample app servers (<em>ch3/ansible/group_vars/sample_app_instances.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">ansible_user</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ec2-user</span></span>

<span style="color:#606">ansible_ssh_private_key_file</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ansible-ch3.key</span></span>

<span style="color:#606">ansible_host_key_checking</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">false</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This file configures the user, private key, and host key checking settings for the sample_app_instances group. Now you

can use a playbook to configure the servers in this group to run the Node.js sample app. Create a new playbook called

<em>configure_sample_app_playbook.yml</em>, with the contents shown in

<a href="04.html#example_ansible_configure_sample_app_playbook_multiple_servers">Example 30</a>:</p>

</div>

<div id="example_ansible_configure_sample_app_playbook_multiple_servers" class="exampleblock">

<div class="title">Example 30. A playbook for configuring the servers to run the Node.js sample app (<em>ch3/ansible/configure_sample_app_playbook.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Configure servers to run the sample-app</span></span>

  <span style="color:#606">hosts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample_app_instances </span></span># <b class="conum">(1)</b>

  <span style="color:#606">gather_facts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

  <span style="color:#606">become</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

  <span style="color:#606">roles</span>:

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">role: nodejs-app        </span></span># <b class="conum">(2)</b>

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">role: sample-app        </span></span># <b class="conum">(3)</b>

      <span style="color:#606">become_user</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">app-user   </span></span># <b class="conum">(4)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Here&#8217;s what this playbook does:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Target the sample_app_instances group you just configured in your inventory.</p>

</li>

<li>

<p>Instead of a single sample-app role that does everything, as you saw in <a href="03.html#example_deploy_ec2_using_ansible">Section 2.3.2.1</a>, the

code in this blog post uses two roles. The first role, called nodejs-app, is responsible for

configuring a server to run Node.js apps. You&#8217;ll see the code for this role shortly.</p>

</li>

<li>

<p>The second role is called sample-app, and it&#8217;s responsible for running the sample-app. You&#8217;ll see the code

for this role shortly as well.</p>

</li>

<li>

<p>The sample-app role will be executed as the OS user <code>app-user</code>, which is a user that the nodejs-app role creates,

rather than as the root user.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>The nodejs-app role contains just a single file and folder, <em>tasks/main.yml</em>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>roles

  ├── nodejs-app

  │   └── tasks

  │       └── main.yml

  └── sample-app</pre>

</div>

</div>

<div class="paragraph">

<p>Create  <em>tasks/main.yml</em> with the contents shown in <a href="04.html#example_ansible_ec2_instances_roles_nodejs_app">Example 31</a>:</p>

</div>

<div id="example_ansible_ec2_instances_roles_nodejs_app" class="exampleblock">

<div class="title">Example 31. The tasks of the nodejs-app role (<em>ch3/ansible/roles/nodejs-app/tasks/main.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"># <b class="conum">(1)</b>

- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Add Node packages to yum</span></span>

  <span style="color:#606">shell</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">curl -fsSL https://rpm.nodesource.com/setup_21.x | bash -</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Install Node.js</span></span>

  <span style="color:#606">yum</span>:

    <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nodejs</span></span>



# <b class="conum">(2)</b>

- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Create app user</span></span>

  <span style="color:#606">user</span>:

    <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">app-user</span></span>



# <b class="conum">(3)</b>

- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Install pm2</span></span>

  <span style="color:#606">npm</span>:

    <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">pm2</span></span>

    <span style="color:#606">version</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">latest</span></span>

    <span style="color:#606">global</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Configure pm2 to run at startup as the app user</span></span>

  <span style="color:#606">shell</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">eval &quot;$(sudo su app-user bash -c 'pm2 startup' | tail -n1)&quot;</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Here&#8217;s what this role does:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Install Node.js, just as you&#8217;ve seen before.</p>

</li>

<li>

<p>Create a new OS user called <code>app-user</code>. This allows you to run your apps with a user with more limited permissions

than root or ec2-user (who can use <code>sudo</code> to access root permissions).</p>

</li>

<li>

<p>Install PM2 and configure it to run on boot. You&#8217;ll see what PM2 is and why it&#8217;s installed shortly.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>As you can see, the nodejs-app role is fairly generic: it&#8217;s designed so you can use it with any Node.js app, which

makes this a highly reusable piece of code.</p>

</div>

<div class="paragraph">

<p>The sample-app role, on the other hand, is specifically designed to run the sample app. Here&#8217;s the folder structure

for this role:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>roles

  ├── nodejs-app

  └── sample-app

      ├── files

      │   ├── app.config.js

      │   └── app.js

      └── tasks

          └── main.yml</pre>

</div>

</div>

<div class="paragraph">

<p><em>files/app.js</em> should be the same sample app code you saw in <a href="02.html#example_node_js_sample_app">Example 1</a> and earlier in

this post. <em>app.config.js</em> is a new file that is used to configure PM2. So, what is PM2?</p>

</div>

<div class="paragraph">

<p><a href="https://pm2.keymetrics.io/">PM2</a> is a <em>process supervisor</em>, which is a tool you can use to run your apps, monitor them,

restart them after a reboot or a crash, manage their logging, and so on. Process supervisors provide one layer of <em>auto

healing</em> for long-running apps. You&#8217;ll see other types of auto healing later in this post.</p>

</div>

<div class="paragraph">

<p>There are many process supervisors out there, including <a href="http://supervisord.org/">supervisord</a>,

<a href="https://smarden.org/runit/">runit</a>, and <a href="https://systemd.io/">systemd</a>, with systemd as the one you&#8217;re likely to use in

most situations, as it&#8217;s built into most Linux distributions these days. However, I picked PM2 for this example because

it has features designed specifically for Node.js apps. To use these features, create a configuration file called

<em>app.config.js</em>, as shown in <a href="04.html#example_ansible_pm2_config">Example 32</a>:</p>

</div>

<div id="example_ansible_pm2_config" class="exampleblock">

<div class="title">Example 32. PM2 configuration file (<em>ch3/ansible/roles/sample-app/files/app.config.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">module.exports = {

  <span style="color:#606">apps</span> : [{

    <span style="color:#606">name</span>   : <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">sample-app</span><span style="color:#710">&quot;</span></span>,

    <span style="color:#606">script</span> : <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">./app.js</span><span style="color:#710">&quot;</span></span>,       // <b class="conum">(1)</b>

    <span style="color:#606">exec_mode</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">cluster</span><span style="color:#710">&quot;</span></span>,      // <b class="conum">(2)</b>

    <span style="color:#606">instances</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">max</span><span style="color:#710">&quot;</span></span>,          // <b class="conum">(3)</b>

    <span style="color:#606">env</span>: {

      <span style="color:#606"><span style="color:#404">&quot;</span><span>NODE_ENV</span><span style="color:#404">&quot;</span></span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">production</span><span style="color:#710">&quot;</span></span> // <b class="conum">(4)</b>

    }

  }]

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This file configures PM2 to do the following:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Run <em>app.js</em> as the Node.js app.</p>

</li>

<li>

<p>Run in <a href="https://nodejs.org/api/cluster.html">cluster mode</a>, so that instead of a single Node.js process, you get one

process per CPU, ensuring your app is able to take advantage of all the CPUs on your server.</p>

</li>

<li>

<p>Use all CPUs available in cluster mode.</p>

</li>

<li>

<p>Set the <code>NODE_ENV</code> environment variable to "production," which is how all Node.js apps and plugins know to run in

production mode rather than development mode.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Finally, create <em>tasks/main.yml</em> with the contents shown in <a href="04.html#example_ansible_role_sample_app_tasks">Example 33</a>:</p>

</div>

<div id="example_ansible_role_sample_app_tasks" class="exampleblock">

<div class="title">Example 33. The sample-app role&#8217;s tasks (<em>ch3/ansible/roles/sample-app/tasks/main.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Copy sample app                          </span></span># <b class="conum">(1)</b>

  <span style="color:#606">copy</span>:

    <span style="color:#606">src</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">./</span></span>

    <span style="color:#606">dest</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">/home/app-user/</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Start sample app using pm2               </span></span># <b class="conum">(2)</b>

  <span style="color:#606">shell</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">pm2 start app.config.js</span></span>

  <span style="color:#606">args</span>:

    <span style="color:#606">chdir</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">/home/app-user/</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Save pm2 app list so it survives reboot  </span></span># <b class="conum">(3)</b>

  <span style="color:#606">shell</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">pm2 save</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Copy the sample app code (<em>app.js</em> and <em>app.config.js</em>) from the <em>files</em> folder to the server.</p>

</li>

<li>

<p>Use PM2 to start the app in the background and start monitoring it.</p>

</li>

<li>

<p>Save the list of apps PM2 is running so that if the server reboots, PM2 will automatically restart those apps.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>These changes address most of the concerns in <a href="02.html#simplified_example_not_for_prod">These are simplified examples for learning, not for production (watch out for snakes!)</a>, improving your security posture

(no more root user) and the reliability and performance of your app (process supervisor, cluster mode).</p>

</div>

<div class="paragraph">

<p>To try this code out, make sure you have Ansible installed, authenticate to AWS as described in

<a href="03.html#example_authenticate_on_the_cli">Section 2.2</a>, and run the following command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v -i inventory.aws_ec2.yml configure_sample_app_playbook.yml</pre>

</div>

</div>

<div class="paragraph">

<p>Ansible will discover your servers, configure each one with all the dependencies it needs, and run the app on each

one. At the end, you should see the IP addresses of servers, as shown in the following log output (truncated

for readability):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>PLAY RECAP ************************************

13.58.56.201               : ok=9    changed=8

3.135.188.118              : ok=9    changed=8

3.21.44.253                : ok=9    changed=8

localhost                  : ok=6    changed=4</pre>

</div>

</div>

<div class="paragraph">

<p>Copy the IP of one of the three servers, open "http://&lt;IP&gt;:8080" in your web browser, and you should see the

familiar "Hello, World!" text once again.</p>

</div>

<div class="paragraph">

<p>While three servers is great for redundancy, it&#8217;s not so great for usability. You typically want to give your users

just a single IP to hit (or better yet, a single domain name, as you&#8217;ll see in <a href="07.html#how_to_set_up_networking">Part 6</a>). This

requires deploying a load balancer, as described in the next section.</p>

</div>

</div>

<div class="sect4">

<h4 id="example_ansible_load_balancing">Example: load balancing using Ansible and Nginx</h4>

<div class="paragraph">

<p>A <em>load balancer</em> is a piece of software that can distribute load across multiple servers or apps. You give your users

a single endpoint to hit, which is the load balancer, and under the hood, the load balancer forwards on requests to

a number of different endpoints, using various algorithms (e.g., round-robin, hash-based, least-response-time, etc.) to

process requests as efficiently as possible. There are many popular load balancer options out there, such as

<a href="https://www.apache.org/">Apache</a>, <a href="https://www.nginx.com/">Nginx</a>, and <a href="https://www.haproxy.org/">HAProxy</a>, as well as

cloud-specific load balancers, such as the <a href="https://aws.amazon.com/elasticloadbalancing/">AWS Elastic Load Balancers</a>,

<a href="https://cloud.google.com/load-balancing?hl=en">GCP Cloud Load Balancers</a>, and

<a href="https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview">Azure Load Balancers</a>.</p>

</div>

<div class="paragraph">

<p>In the cloud, you&#8217;d most likely use a cloud load balancer, as you&#8217;ll see later in this blog post.

However, for the purposes of server orchestration, I decided to show you a simplified example of how to run your own

load balancer, as server orchestration techniques should work on-prem as well. Therefore, you&#8217;ll be deploying Nginx.</p>

</div>

<div class="paragraph">

<p>To do that, you need one more server. If you have one already with SSH access, you can use it, and skip forward a few

paragraphs. If not, you can deploy one more EC2 instance using the same <em>create_ec2_instances_playbook.yml</em>, but with a

new variables file, <em>nginx-vars.yml</em>, with the contents shown in <a href="04.html#example_ansible_nginx_vars_file">Example 34</a>:</p>

</div>

<div id="example_ansible_nginx_vars_file" class="exampleblock">

<div class="title">Example 34. Variables file to create an EC2 instance for nginx (<em>ch3/ansible/nginx-vars.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">num_instances</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">1</span></span>

<span style="color:#606">base_name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nginx_instances</span></span>

<span style="color:#606">http_port</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">80</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This will create a single EC2 instance, with the <code>base_name</code> "nginx_instances," and it will allow requests on port 80,

which is the default port for HTTP. Run the playbook with this vars file as follows:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v create_ec2_instances_playbook.yml --extra-vars "@nginx-vars.yml"</pre>

</div>

</div>

<div class="paragraph">

<p>This should create one more EC2 instance you can use for nginx. Since the <code>base_name</code> for that instance is

<code>nginx_instances</code>, that will also be the group name in the inventory, so configure the variables for this group by

creating <em>group_vars/nginx_instances.yml</em> with the contents shown in <a href="04.html#example_ansible_group_vars_nginx">Example 35</a>:</p>

</div>

<div id="example_ansible_group_vars_nginx" class="exampleblock">

<div class="title">Example 35. Configure group variables for your Nginx servers (<em>ch3/ansible/group_vars/nginx_instances.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">ansible_user</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ec2-user</span></span>

<span style="color:#606">ansible_ssh_private_key_file</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">ansible-ch3.key</span></span>

<span style="color:#606">ansible_host_key_checking</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">false</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Now you can create a new playbook to configure these servers with Nginx. Create a new file called

<em>configure_nginx_playbook.yml</em> with the contents shown in <a href="04.html#example_ansible_ec2_for_nginx_role">Example 36</a>:</p>

</div>

<div id="example_ansible_ec2_for_nginx_role" class="exampleblock">

<div class="title">Example 36. Use a role to configure the EC2 instance with Nginx (<em>ch3/ansible/configure_nginx_playbook.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Configure servers to run nginx</span></span>

  <span style="color:#606">hosts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nginx_instances </span></span># <b class="conum">(1)</b>

  <span style="color:#606">gather_facts</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

  <span style="color:#606">become</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

  <span style="color:#606">roles</span>:

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">role: nginx        </span></span># <b class="conum">(2)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This playbook does the following:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Target the <code>nginx_instances</code> group you just configured in your inventory.</p>

</li>

<li>

<p>Configure the servers in that group using a new role called nginx, which is described next.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>The nginx role has the following folder structure:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>roles

  ├── nginx

  │   ├── tasks

  │   │   └── main.yml

  │   └── templates

  │       └── nginx.conf.j2

  ├── nodejs-app

  └── sample-app</pre>

</div>

</div>

<div class="paragraph">

<p>Inside of <em>nginx/templates/nginx.conf.j2</em>, create an Nginx configuration file template, as shown in

<a href="04.html#example_ansible_nginx_config_template">Example 37</a>:</p>

</div>

<div id="example_ansible_nginx_config_template" class="exampleblock">

<div class="title">Example 37. Nginx configuration file template (<em>ch3/ansible/roles/nginx/templates/nginx.conf.j2</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="nginx">user nginx;

worker_processes auto;

error_log /var/log/nginx/error.log notice;

pid /run/nginx.pid;



events {

    worker_connections 1024;

}



http {

    log_format  main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '

                      '$status $body_bytes_sent &quot;$http_referer&quot; '

                      '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';



    access_log  /var/log/nginx/access.log  main;



    include             /etc/nginx/mime.types;

    default_type        application/octet-stream;



    upstream backend {                                       # <b class="conum">(1)</b>

        {% for host in groups['sample_app_instances'] %}     # <b class="conum">(2)</b>

        server {{ hostvars[host]['public_dns_name'] }}:8080; # <b class="conum">(3)</b>

        {% endfor %}

    }



    server {

        listen       80;                                     # <b class="conum">(4)</b>

        listen       [::]:80;



        location / {                                         # <b class="conum">(5)</b>

                proxy_pass http://backend;

        }

    }

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Most of this file is standard

<a href="https://docs.nginx.com/nginx/admin-guide/basic-functionality/managing-configuration-files/">Nginx configuration</a>, but

there are a few items that you should take note of:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Use the <em>upstream</em> keyword to define a group of servers that can be referenced elsewhere in this file by the name

"backend." You&#8217;ll see where this is used shortly.</p>

</li>

<li>

<p>Use <a href="https://jinja.palletsprojects.com/en/3.1.x/">Jinja</a> templating syntax to loop over the servers in the

sample_app_instances group.</p>

</li>

<li>

<p>Use Jinja templating syntax to configure the upstream named backend to route traffic to the public address and

port 8080 of each server in the sample_app_instances group.</p>

</li>

<li>

<p>Configure Nginx to listen on port 80.</p>

</li>

<li>

<p>Configure Nginx as a load balancer, forwarding requests to the / URL to the upstream named backend.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>In short, the preceding configuration file will configure Nginx to load balance traffic across the servers

you deployed to run the sample app.</p>

</div>

<div class="paragraph">

<p>In <em>nginx/tasks/main.yml</em>, configure the tasks for the nginx role with the contents shown in

<a href="04.html#example_ansible_nginx_task">Example 38</a>:</p>

</div>

<div id="example_ansible_nginx_task" class="exampleblock">

<div class="title">Example 38. Nginx role tasks (<em>ch3/ansible/roles/nginx/tasks/main.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Install Nginx              </span></span># <b class="conum">(1)</b>

  <span style="color:#606">yum</span>:

    <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nginx</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Copy Nginx config          </span></span># <b class="conum">(2)</b>

  <span style="color:#606">template</span>:

    <span style="color:#606">src</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nginx.conf.j2</span></span>

    <span style="color:#606">dest</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">/etc/nginx/nginx.conf</span></span>



- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Start Nginx                </span></span># <b class="conum">(3)</b>

  <span style="color:#606">systemd_service</span>:

    <span style="color:#606">state</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">started</span></span>

    <span style="color:#606">enabled</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">true</span></span>

    <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">nginx</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The tasks in the Nginx role are:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Install Nginx.</p>

</li>

<li>

<p>Render the Nginx configuration file and copy it to the server.</p>

</li>

<li>

<p>Start Nginx. Note the use of <code>systemd</code> as a process supervisor to restart Nginx in case it crashes or the server

reboots.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Run this playbook to configure Nginx:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v -i inventory.aws_ec2.yml configure_nginx_playbook.yml</pre>

</div>

</div>

<div class="paragraph">

<p>Wait a few minutes for everything to deploy and in the end, you should see log output that looks like this:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>PLAY RECAP

xxx.us-east-2.compute.amazonaws.com : ok=4    changed=2    failed=0</pre>

</div>

</div>

<div class="paragraph">

<p>The value on the left, "xxx.us-east-2.compute.amazonaws.com," is a domain name you can use to access the Nginx server.

If you open <a href="http://xxx.us-east-2.compute.amazonaws.com" class="bare">http://xxx.us-east-2.compute.amazonaws.com</a> (this time with no port number, as Nginx is listening on port 80,

the default port for HTTP) in your browser, you should see "Hello, World!" yet again. Each time you refresh the page,

Nginx will send that request to a different EC2 instance. Congrats, you now have a single endpoint you can give your

users, and it will automatically balance the load across multiple servers!</p>

</div>

</div>

<div class="sect4">

<h4 id="example_ansible_rolling_updates">Example: rolling out updates with Ansible</h4>

<div class="paragraph">

<p>So you&#8217;ve now seen how to deploy using a server orchestration tool, but what about doing an update? Some configuration

management tools support various <em>deployment strategies</em> (a topic you&#8217;ll learn more about in <a href="06.html#how_to_set_up_ci_cd">Part 5</a>),

such as a <em>rolling deployment</em>, where you update your servers in batches, so some servers are always running and

serving traffic, while others are being updated. With Ansible, the easiest way to have it do a rolling update is to add

the <code>serial</code> parameter to <em>configure_sample_app_playbook.yml</em>, as shown in <a href="04.html#example_ansible_ec2_instances_serial">Example 39</a>:</p>

</div>

<div id="example_ansible_ec2_instances_serial" class="exampleblock">

<div class="title">Example 39. Use the serial parameter to enable rolling deployment (<em>ch3/ansible/configure_sample_app_playbook.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml">- <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: Configure servers to run the sample-app</span></span>



  <span style="color:#777"># ... (other params omitted for clarity) ...</span>



  <span style="color:#606">serial</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">1               </span></span># <b class="conum">(1)</b>

  <span style="color:#606">max_fail_percentage</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">30 </span></span># <b class="conum">(2)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Setting <code>serial</code> to 1 tells Ansible to apply changes to one server at a time. Since you have three servers total,

this ensures that two servers are always available to serve traffic, while one goes down briefly for an update.</p>

</li>

<li>

<p>The <code>max_fail_percentage</code> parameter tells Ansible to abort a deployment if more than this percent of servers hit an

error during upgrade. Setting this to 30% with three servers means that if a single server fails to update,

Ansible will not try to deploy the changes to any other servers, so you never lose more than one server to a broken

update.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Let&#8217;s give the rolling deployment a shot. Update the text that the app responds with in <em>app.js</em>, as shown in

<a href="04.html#example_ansible_ec2_updated_response">Example 40</a>:</p>

</div>

<div id="example_ansible_ec2_updated_response" class="exampleblock">

<div class="title">Example 40. Update the app to respond with the text "Fundamentals of DevOps!" (<em>ch3/ansible/roles/sample-app/files/app.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">  res.end(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">Fundamentals of DevOps!</span><span style="color:#D20">\n</span><span style="color:#710">'</span></span>);</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>And re-run the playbook:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ ansible-playbook -v -i inventory.aws_ec2.yml configure_sample_app_playbook.yml</pre>

</div>

</div>

<div class="paragraph">

<p>You should see Ansible rolling out the change to one server at a time. When it&#8217;s done, if you refresh the Nginx IP in

your browser, you should see the text "Fundamentals of DevOps!"</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Get your hands dirty</div>

<div class="paragraph">

<p>Here are a few exercises you can try at home to get a better feel for using Ansible for server orchestration:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>If you wanted to add a fourth EC2 instance to run your apps, what changes would you have to make to

<em>create_ec2_instances_playbook.yml</em>? What about <em>configure_nginx_playbook.yml</em>?</p>

</li>

<li>

<p>Try restarting one of the EC2 instances using the AWS Console. How does nginx handle it while the instance is

rebooting? Does the sample-app still work after the reboot? How does this compare to the behavior you saw in

<a href="02.html#how_to_deploy_your_app">Part 1</a>?</p>

</li>

<li>

<p>Try terminating one of the EC2 instances using the AWS Console. How does nginx handle it? How can you restore the

instance?</p>

</li>

</ul>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>When you&#8217;re done experimenting with Ansible, you should manually undeploy the EC2 instances by finding each one in the

<a href="https://console.aws.amazon.com/ec2/home">EC2 Console</a> (look for the instance IDs the playbook writes to the log),

clicking "Instance state," and choosing "Terminate instance" in the drop down, as shown in <a href="02.html#ec2_terminate_instance">Figure 9</a>.

This ensures that your account doesn&#8217;t start accumulating any unwanted charges.</p>

</div>

</div>

</div>

</div>

<div class="sect2">

<h2 id="_vm_orchestration">VM orchestration</h2>

<div class="paragraph">

<p>The idea with <em>VM orchestration</em> is to do the following:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Create VM images that have your apps and all their dependencies fully installed and configured.</p>

</li>

<li>

<p>Deploy the VM images across a cluster of servers.</p>

</li>

<li>

<p>Scale the number of servers up or down depending on your needs.</p>

</li>

<li>

<p>When you need to deploy an update, create new VM images, deploy those onto new servers, and then undeploy the old

servers.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>This is a slightly more modern approach that works best with cloud providers such as AWS, GCP, and Azure, where the

servers are all virtual servers, so you can spin up new ones and tear down old ones in minutes. That said, you can also

use virtualization on-prem, with VMWare as the dominant player in that space. We&#8217;ll take a look at a VM orchestration

example using AWS, but be aware that the basic techniques here apply to most VM orchestration tools, whether in the

cloud or on-prem.</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Key takeaway #2</div>

<div class="paragraph">

<p>VM orchestration is an immutable infrastructure approach where you deploy and manage VM images across virtualized

servers.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="sect3">

<h3 id="example_vm_orchestration">Example: VM orchestration using Packer, OpenTofu, and AWS Auto Scaling Groups</h3>

<div class="paragraph">

<p>To get a feel for VM orchestration, you need three things:</p>

</div>

<div class="olist arabic">

<ol class="arabic">

<li>

<p><strong>A tool for building VM images</strong>: Just as in <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>, you&#8217;ll use Packer to create VM

images for AWS.</p>

</li>

<li>

<p><strong>A tool for orchestrating VMs</strong>: This blog post series primarily uses AWS, so you&#8217;ll use AWS' VM orchestration tool,

Auto Scaling Groups.</p>

</li>

<li>

<p><strong>A tool for managing your infrastructure as code</strong>: Instead of setting up Auto Scaling Groups by manually clicking

around, you&#8217;ll use the same IaC tool as in <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>, OpenTofu, to manage your

infrastructure as code.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>We&#8217;ll start with the first item, building VM images.</p>

</div>

<div class="sect4">

<h4 id="_example_building_vm_images_using_packer">Example: building VM images using Packer</h4>

<div class="paragraph">

<p>Head into the <em>fundamentals-of-devops</em> folder you created in <a href="02.html#how_to_deploy_your_app">Part 1</a> to work through the

examples in this blog post series, and create a new subfolder for the Packer code:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/packer

$ cd ch3/packer</pre>

</div>

</div>

<div class="paragraph">

<p>Copy the Packer template you created in <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a> into the new <em>ch3/packer</em> folder:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cp ../../ch2/packer/sample-app.pkr.hcl .</pre>

</div>

</div>

<div class="paragraph">

<p>You should also copy <em>app.js</em> (the sample app) and <em>app.config.js</em> (the PM2 configuration file) from the server

orchestration section of this blog post into the <em>ch3/packer</em> folder:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cp ../ansible/roles/sample-app/files/app*.js .</pre>

</div>

</div>

<div class="paragraph">

<p><a href="04.html#example_packer_template_security_updates">Example 41</a> shows the updates to make to the Packer template:</p>

</div>

<div id="example_packer_template_security_updates" class="exampleblock">

<div class="title">Example 41. Update the Packer template to use PM2 as a process supervisor and create <code>app-user</code> (<em>ch3/packer/sample-app.pkr.hcl</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="hcl">build {

  sources = [

    &quot;source.amazon-ebs.amazon_linux&quot;

  ]



  provisioner &quot;file&quot; {                                                   # <b class="conum">(1)</b>

    sources     = [&quot;app.js&quot;, &quot;app.config.js&quot;]

    destination = &quot;/tmp/&quot;

  }



  provisioner &quot;shell&quot; {

    inline = [

      &quot;curl -fsSL https://rpm.nodesource.com/setup_21.x | sudo bash -&quot;,

      &quot;sudo yum install -y nodejs&quot;,

      &quot;sudo adduser app-user&quot;,                                           # <b class="conum">(2)</b>

      &quot;sudo mv /tmp/app.js /tmp/app.config.js /home/app-user/&quot;,          # <b class="conum">(3)</b>

      &quot;sudo npm install pm2@latest -g&quot;,                                  # <b class="conum">(4)</b>

      &quot;eval \&quot;$(sudo su app-user bash -c 'pm2 startup' | tail -n1)\&quot;&quot;    # <b class="conum">(5)</b>

    ]

    pause_before = &quot;30s&quot;

  }

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The main changes are to make similar security and reliability improvements to the ones in the server orchestration

section: that is, use PM2 as a process supervisor and create <code>app-user</code> to run the app (instead of using the root

user).</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Copy two files, <em>app.js</em> and <em>app.config.js</em>, onto the server (into the  <em>/tmp</em> folder, as the final destination,

the home folder of <code>app-user</code>, doesn&#8217;t exist until a later step).</p>

</li>

<li>

<p>Create <code>app-user</code>. This will also automatically create a home folder for <code>app-user</code>.</p>

</li>

<li>

<p>Copy <em>app.js</em> and <em>app.config.js</em> from the <em>/tmp</em> folder to the home folder of <code>app-user</code>.</p>

</li>

<li>

<p>Install PM2.</p>

</li>

<li>

<p>Configure PM2 to run on boot (as <code>app-user</code>) so if your server ever restarts, PM2 will restart your app.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>To build the AMI, make sure Packer is installed, authenticate to AWS as described in

<a href="03.html#example_authenticate_on_the_cli">Section 2.2</a>, and run the following commands:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ packer init

$ packer build sample-app.pkr.hcl</pre>

</div>

</div>

<div class="paragraph">

<p>When the build is done, Packer will output the ID of the newly created AMI. Make sure to jot this down somewhere, as

you&#8217;ll need it shortly.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_deploying_vm_images_in_aws_using_opentofu_and_auto_scaling_groups">Example: deploying VM images in AWS using OpenTofu and Auto Scaling Groups</h4>

<div class="paragraph">

<p>The next step is to deploy the AMI. In <a href="03.html#how_to_manage_your_infra_as_code">Part 2</a>, you used OpenTofu to deploy an AMI on a

single EC2 instance. The goal now is to see VM orchestration at play, which means deploying multiple servers, or what&#8217;s

sometimes called a <em>cluster</em>. Most cloud providers offer a native way to run VMs across a cluster: for example, AWS

offers <em>Auto Scaling Groups (ASG)</em>, GCP offers <em>Managed Instance Groups</em>, and Azure offers <em>Scale Sets</em>. For this

example, you&#8217;ll be using an AWS ASG, as that offers a number of nice features:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Cluster management</dt>

<dd>

<p>ASGs make it easy to launch multiple instances and manually resize the cluster at any time.</p>

</dd>

<dt class="hdlist1">Auto scaling</dt>

<dd>

<p>You can also configure the ASG to automatically resize cluster in response to load.</p>

</dd>

<dt class="hdlist1">Auto healing</dt>

<dd>

<p>The ASG monitors all the instances in the cluster and automatically replaces any instance that

crashes.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>Let&#8217;s use a reusable module (as introduced in <a href="03.html#opentofu_reusable_module">Section 2.3.5.3</a>) called <code>asg</code> from this blog post series&#8217;s

<a href="https://github.com/brikis98/fundamentals-of-devops-code">sample code repo</a> to deploy an ASG. You can find the module in the <em>ch3/tofu/modules/asg</em>

folder. This is a simple module that creates three main resources:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>A <em>launch template</em>, which is a bit like a blueprint that specifies the configuration to use for each EC2 instance.</p>

</li>

<li>

<p>An ASG which uses the configuration in the launch template to stamp out EC2 instances. The ASG will deploy these

instances into the <em>Default VPC</em>. See the note on Default VPCs in <a href="04.html#default_vpc">A Note on Default Virtual Private Clouds</a>.</p>

</li>

<li>

<p>A security group which controls the traffic that can go in and out of each EC2 instance.</p>

</li>

</ul>

</div>

<div id="default_vpc" class="admonitionblock note">

<table>

<tr>

<td class="icon">

<div class="title">Note</div>

</td>

<td class="content">

<div class="title">A Note on Default Virtual Private Clouds</div>

<div class="paragraph">

<p>All the AWS examples in the early parts of this blog post series use the Default VPC in your AWS account. A

<em>VPC</em>, or virtual private cloud, is an isolated area of your AWS account that has its own virtual network and IP address

space. Just about every AWS resource deploys into a VPC. If you don&#8217;t explicitly specify a VPC, the resource will be

deployed into the <em>Default VPC</em>, which is part of every AWS account created after 2013 (if you deleted your Default VPC,

you can create a new Default VPC using the <a href="https://console.aws.amazon.com/vpc/home">VPC Console</a>). It&#8217;s not a good idea

to use the Default VPC for production apps, but it&#8217;s OK to use it for learning and testing. In

<a href="07.html#how_to_set_up_networking">Part 6</a>, you&#8217;ll learn more about VPCs, including how to create a custom VPC that you can use for

production apps instead of the Default VPC.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>To use the <code>asg</code> module, create a <em>live/asg-sample</em> folder to act as a root module:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/tofu/live/asg-sample

$ cd ch3/tofu/live/asg-sample</pre>

</div>

</div>

<div class="paragraph">

<p>Inside the <em>asg-sample</em> folder, create a <em>main.tf</em> file with the initial contents shown in

<a href="04.html#sample_app_asg_main_initial">Example 42</a>:</p>

</div>

<div id="sample_app_asg_main_initial" class="exampleblock">

<div class="title">Example 42. Configure the <code>asg</code> module (<em>ch3/tofu/live/asg-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">provider &quot;aws&quot; {

  region = &quot;us-east-2&quot;

}



module &quot;asg&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/asg&quot;



  name = &quot;sample-app-asg&quot;                                   # <b class="conum">(1)</b>



  # TODO: fill in with your own AMI ID!

  ami_id        = &quot;ami-0f5b3d9c244e6026d&quot;                   # <b class="conum">(2)</b>

  user_data     = filebase64(&quot;${path.module}/user-data.sh&quot;) # <b class="conum">(3)</b>

  app_http_port = 8080                                      # <b class="conum">(4)</b>



  instance_type    = &quot;t2.micro&quot;                             # <b class="conum">(5)</b>

  min_size         = 1                                      # <b class="conum">(6)</b>

  max_size         = 10                                     # <b class="conum">(7)</b>

  desired_capacity = 3                                      # <b class="conum">(8)</b>

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code sets the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>name</code>: The name to use for the launch template, ASG, security group, and all other resources created by the module.</p>

</li>

<li>

<p><code>ami_id</code>: The AMI to use for each EC2 instance. You&#8217;ll need to set this to the ID of the AMI you built from the

Packer template in the previous section.</p>

</li>

<li>

<p><code>user_data</code>: The user data script to run on each instance during boot. The contents of <em>user-data.sh</em> are shown in

<a href="04.html#sample_app_asg_user_data">Example 43</a>.</p>

</li>

<li>

<p><code>app_http_port</code>: The port to open in the security group to allow the app to receive HTTP requests.</p>

</li>

<li>

<p><code>instance_type</code>: The type of instances to run in the ASG.</p>

</li>

<li>

<p><code>min_size</code>: The minimum number of instances to run in the ASG.</p>

</li>

<li>

<p><code>max_size</code>: The maximum number of instances to run in the ASG.</p>

</li>

<li>

<p><code>desired_capacity</code>: The initial number of instances to run in the ASG.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Create a file called <em>user-data.sh</em> with the contents shown in <a href="04.html#sample_app_asg_user_data">Example 43</a>:</p>

</div>

<div id="sample_app_asg_user_data" class="exampleblock">

<div class="title">Example 43. The user data script for each EC2 instance, which uses PM2 to start the sample-app (<em>ch3/tofu/live/asg-sample/user-data.sh</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="bash">#!/usr/bin/env bash



set -e



sudo su app-user         # <b class="conum">(1)</b>

cd /home/app-user        # <b class="conum">(2)</b>

pm2 start app.config.js  # <b class="conum">(3)</b>

pm2 save                 # <b class="conum">(4)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This user data script does the following:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>Switch to <code>app-user</code>.</p>

</li>

<li>

<p>Go into the home folder for <code>app-user</code>, which is where the Packer template copied the sample app code.</p>

</li>

<li>

<p>Use PM2 to run the sample app.</p>

</li>

<li>

<p>Save the running app status so that if the server reboots, PM2 will restart the sample app.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>If you were to run <code>apply</code> right now, you&#8217;d get an ASG with three EC2 instances running your sample app. While this is

great for redundancy, as discussed in the server orchestration section, you typically want to give your users just a

single endpoint to hit. This requires deploying a load balancer, as described in the next section.</p>

</div>

</div>

<div class="sect4">

<h4 id="example_aws_load_balancing">Example: load balancing using OpenTofu and AWS</h4>

<div class="paragraph">

<p>In the server orchestration section, you deployed your own load balancer using Nginx. This was a very simplified

deployment that works fine for an example, but has a number of drawbacks if you try to use it for production apps:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Availability</dt>

<dd>

<p>You are running only a single instance for your load balancer. If it crashes, your users experience

an outage.</p>

</dd>

<dt class="hdlist1">Scalability</dt>

<dd>

<p>If load exceeds what a single server can handle, users will see degraded performance or an outage.</p>

</dd>

<dt class="hdlist1">Maintenance</dt>

<dd>

<p>Keeping the load balancer up to date is entirely up to you. Moreover, when you need to update the

load balancer itself (e.g., update to a new version of Nginx), it&#8217;s tricky to do so without downtime.</p>

</dd>

<dt class="hdlist1">Security</dt>

<dd>

<p>The load balancer server is not especially hardened against attacks.</p>

</dd>

<dt class="hdlist1">Encryption</dt>

<dd>

<p>If you want to encrypt data in transit (e.g., use HTTPS and TLS)—which you should for just about all

production use cases—you&#8217;ll have to set it all up manually (you&#8217;ll learn more about encryption in

<a href="08.html#how_to_manage_auth_and_secrets">Part 7</a>).</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>To be clear, there&#8217;s nothing wrong with Nginx: if you put the work in, there are ways to address all of these issues

with Nginx. However, it&#8217;s a considerable amount of work. One of the big benefits of the cloud is that most cloud

providers offer <em>managed services</em> that can do this work for you. Load balancing is a very common problem,

and as I mentioned before, almost every cloud provider offers a managed service for load balancing, such as

<a href="https://aws.amazon.com/elasticloadbalancing/">AWS Elastic Load Balancers</a>,

<a href="https://cloud.google.com/load-balancing?hl=en">GCP Cloud Load Balancers</a>, and

<a href="https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview">Azure Load Balancers</a>. All of these

provide a number of powerful features out-of-the-box. For example, the AWS Elastic Load Balancer (ELB) gives you the

following:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Availability</dt>

<dd>

<p>under the hood, AWS automatically deploys multiple servers for an ELB so you don&#8217;t get an outage

if one server crashes.</p>

</dd>

<dt class="hdlist1">Scalability</dt>

<dd>

<p>AWS monitors load on the ELB, and if it is starting to exceed capacity, AWS automatically deploys more

servers.</p>

</dd>

<dt class="hdlist1">Maintenance</dt>

<dd>

<p>AWS automatically keeps the load balancer up to date, with zero downtime.</p>

</dd>

<dt class="hdlist1">Security</dt>

<dd>

<p>AWS load balancers are hardened against a variety of attacks, including meeting the requirements of a

variety of security standards (e.g., SOC 2, ISO 27001, HIPAA, PCI, FedRAMP) out-of-the-box (see

<a href="https://aws.amazon.com/compliance/services-in-scope/">AWS Services in Scope by Compliance Program</a>).</p>

</dd>

<dt class="hdlist1">Encryption</dt>

<dd>

<p>AWS has out-of-the-box support for HTTPS, Mutual TLS, TLS Offloading, auto-rotated TLS certs, and

more.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>Using a managed service for load balancing can be a huge time saver, so let&#8217;s use an AWS load balancer. There are

actually several types of AWS load balancers to choose from; the one that&#8217;ll be the best fit for the simple sample app

is the <a href="https://aws.amazon.com/elasticloadbalancing/application-load-balancer/"><em>Application Load Balancer (ALB)</em></a>. The

ALB consists of several parts, as shown in <a href="04.html#alb_overview">Figure 22</a>:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Listener</dt>

<dd>

<p>Listen for requests on a specific port (e.g., 80) and protocol (e.g., HTTP).</p>

</dd>

<dt class="hdlist1">Listener rule</dt>

<dd>

<p>Specify how which requests that come into a listener to route to which target group based on rules that match on

paths (e.g., <code>/foo</code> and <code>/bar</code>), hostnames (e.g., <code>foo.example.com</code> and <code>bar.example.com</code>), and so on.</p>

</dd>

<dt class="hdlist1">Target groups</dt>

<dd>

<p>One or more servers that receive requests from the load balancer. The target group also performs

<em>health checks</em> on these servers by sending each server a request on a configurable interval (e.g., every 30 seconds),

and only considering the server as healthy if it returns an expected response (e.g., a 200 OK) within a configurable

time period (e.g., within 2 seconds). The target group will only send requests to servers that pass its health checks.</p>

</dd>

</dl>

</div>

<div id="alb_overview" class="imageblock">

<div class="content">

<img src="images/ch3/alb.png" alt="An ALB consists of listeners, listener rules, and target groups">

</div>

<div class="title">Figure 22. An ALB consists of listeners, listener rules, and target groups.</div>

</div>

<div class="paragraph">

<p>The blog post series&#8217;s sample code repo includes a module called <code>alb</code> in the <em>ch3/tofu/modules/alb</em> folder that you

can use to deploy an ALB. Note that this is a very simple ALB—it deploys into the Default VPC (see the note in

<a href="04.html#default_vpc">A Note on Default Virtual Private Clouds</a>) and only has a single listener rule where it forwards all requests to a single target group—but it

should suffice for our purposes in this blog post.</p>

</div>

<div class="paragraph">

<p><a href="04.html#sample_app_asg_main_alb">Example 44</a> shows how to update the <code>asg-sample</code> module to use the <code>alb</code> module:</p>

</div>

<div id="sample_app_asg_main_alb" class="exampleblock">

<div class="title">Example 44. Configure the <code>alb</code> module (<em>ch3/tofu/live/asg-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">module &quot;alb&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/alb&quot;



  name                  = &quot;sample-app-alb&quot; # <b class="conum">(1)</b>

  alb_http_port         = 80               # <b class="conum">(2)</b>

  app_http_port         = 8080             # <b class="conum">(3)</b>

  app_health_check_path = &quot;/&quot;              # <b class="conum">(4)</b>

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code sets the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>name</code>: The name to use for the ALB, target group, security group, and all other resources created by the module.</p>

</li>

<li>

<p><code>alb_http_port</code>: The port the ALB (the listener) listens on for HTTP requests.</p>

</li>

<li>

<p><code>app_http_port</code>: The port the app listens on for HTTP requests. The ALB target group will send traffic and health

checks to this port.</p>

</li>

<li>

<p><code>app_health_check_path</code>: The path to use when sending health check requests to the app.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>The one missing piece is the connection between the ASG and the ALB: that is, how does the ALB know which EC2 instances

to send traffic to (which instances to put in its target group)? To tie these pieces together, go back to your usage

of the <code>asg</code> module, and update it with one parameter, as shown in <a href="04.html#sample_app_asg_main_target_group">Example 45</a>:</p>

</div>

<div id="sample_app_asg_main_target_group" class="exampleblock">

<div class="title">Example 45. Configure the <code>asg</code> module (<em>ch3/tofu/live/asg-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">module &quot;asg&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/asg&quot;



  # ... (other params omitted) ...



  target_group_arns = [module.alb.target_group_arn]

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code sets the <code>target_group_arns</code> parameter, which will change the ASG behavior in two ways:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>First, it&#8217;ll configure the ASG to register all of its instances in the specified target group, including the initial

set of instances when you first launch the ASG, as well as any new instances that launch later, either as a result of

a deployment or auto healing or auto scaling.</p>

</li>

<li>

<p>Second, it&#8217;ll configure the ASG to use the ALB for health checks and auto healing. By default, the auto healing

feature in the ASG is simple: it replaces any instance that has crashed (a hardware issue). However, if the instance

is still running, and it&#8217;s the app that crashed or stopped responding (a software issue), the ASG won&#8217;t know to

replace it. Configuring the ASG to use the ALB for health checks tells the ASG to replace an instance if it fails

the load balancer&#8217;s health check, which gives you more robust auto healing, as the load balancer health check will

detect both hardware and software issues.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>The final change to the <code>asg-sample</code> module is to add the load balancer&#8217;s domain name as an output variable in

<em>outputs.tf</em>, as shown in <a href="04.html#example_asg_output">Example 46</a>:</p>

</div>

<div id="example_asg_output" class="exampleblock">

<div class="title">Example 46. Output the ALB domain name (<em>ch3/tofu/live/asg-sample/outputs.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">output &quot;alb_dns_name&quot; {

  value = module.alb.alb_dns_name

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>To deploy the module, make sure OpenTofu is installed, authenticate to AWS as described in

<a href="03.html#example_authenticate_on_the_cli">Section 2.2</a>, and run the following commands:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu init

$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p>After a few minutes, everything should be deployed, and you should see the ALB domain name as an output:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>Apply complete! Resources: 10 added, 0 changed, 0 destroyed.



Outputs:



alb_dns_name = "sample-app-tofu-656918683.us-east-2.elb.amazonaws.com"</pre>

</div>

</div>

<div class="paragraph">

<p>Open this domain name up in your web browser, and you should see "Hello, World!" once again. Congrats, you now have

a single endpoint, the load balancer domain name, that you can give your users, and when users hit it, the load balancer

will distribute their requests across all your apps in your ASG!</p>

</div>

</div>

<div class="sect4">

<h4 id="example_aws_automatic_rollouts">Example: rolling out updates with OpenTofu and Auto Scaling Groups</h4>

<div class="paragraph">

<p>You&#8217;ve seen the initial deployment with VM orchestration, but what about rolling out updates? Most of the VM

orchestration tools have support for zero-downtime deployments and various deployment strategies. For example, the

ASGs in AWS have native support for a feature called

<a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-instance-refresh.html">instance refresh</a>, which can update

your instances automatically by doing a rolling deployment. <a href="04.html#sample_app_asg_main_instance_refresh">Example 47</a> shows how to enable

instance refresh in the <code>asg</code> module:</p>

</div>

<div id="sample_app_asg_main_instance_refresh" class="exampleblock">

<div class="title">Example 47. Enable instance refresh for the ASG (<em>ch3/tofu/live/asg-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">module &quot;asg&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/asg&quot;



  # ... (other params omitted) ...



  instance_refresh = {

    min_healthy_percentage = 100  # <b class="conum">(1)</b>

    max_healthy_percentage = 200  # <b class="conum">(2)</b>

    auto_rollback          = true # <b class="conum">(3)</b>

  }

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code sets the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>min_healthy_percentage</code>: Setting this to 100% means that the cluster will never have fewer than the desired number

of instances (initially, three), even during deployment. Whereas with server orchestration, you updated instances in

place, with VM orchestration, you&#8217;ll deploy <em>new instances</em>, as per the next parameter.</p>

</li>

<li>

<p><code>max_healthy_percentage</code>: Setting this to 200% means that to deploy updates, the cluster will deploy totally new

instances, up to twice the original size of the cluster, wait for the new instances to pass health checks, and then

undeploy the old instances. So if you started with three instances, then during deployment, you&#8217;ll go up to six

instances, with three new and three old, and when the new instances pass health checks, you&#8217;ll go back to three

instances by undeploying the three old ones.</p>

</li>

<li>

<p><code>auto_rollback</code>: If something goes wrong during deployment, and the new instances fail to pass health checks, this

setting will automatically initiate a rollback, putting your cluster back to its previous working condition.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Run <code>apply</code> one more time to enable the instance refresh setting. Once that&#8217;s done, you can try rolling out a change.

For example, update <em>app.js</em> in the <em>packer</em> folder to respond with "Fundamentals of DevOps!", as shown in

<a href="04.html#example_tofu_ec2_updated_response">Example 48</a>:</p>

</div>

<div id="example_tofu_ec2_updated_response" class="exampleblock">

<div class="title">Example 48. Update the app to respond with the text "Fundamentals of DevOps!" (<em>ch3/packer/app.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">  res.end(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">Fundamentals of DevOps!</span><span style="color:#D20">\n</span><span style="color:#710">'</span></span>);</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Next, build a new AMI using Packer:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ packer build sample-app.pkr.hcl</pre>

</div>

</div>

<div class="paragraph">

<p>This will give you a new AMI ID. Update the <code>ami_id</code> in the <code>asg-sample</code> module to this new ID and run <code>apply</code> one

more time. You should then see a plan output that looks something like this (truncated for readability):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu apply



OpenTofu will perform the following actions:



  # aws_autoscaling_group.sample_app will be updated in-place

  ~ resource "aws_autoscaling_group" "sample_app" {

        # (27 unchanged attributes hidden)



      ~ launch_template {

            id      = "lt-0bc25ef067814e3c0"

            name    = "sample-app-tofu20240414163932598800000001"

          ~ version = "1" -&gt; (known after apply)

        }



        # (3 unchanged blocks hidden)

    }



  # aws_launch_template.sample_app will be updated in-place

  ~ resource "aws_launch_template" "sample_app" {

      ~ image_id                = "ami-0d96232dece796dfb" -&gt; "ami-0d68b7b6546331281"

      ~ latest_version          = 1 -&gt; (known after apply)

        # (10 unchanged attributes hidden)

    }</pre>

</div>

</div>

<div class="paragraph">

<p>This plan output shows that launch template has changed, due to the new AMI ID, and as a result, the version of the

launch template used in the ASG has changed. This will result in an instance refresh. Type in <strong><code>yes</code></strong>, hit Enter, and

AWS will kick off the instance refresh process in the background. If you go to the EC2 Console, click Auto Scaling

Groups in the left nav, find your ASG, and click the "Instance refresh" tab, you should be able to see the instance

refresh in progress, as shown in <a href="04.html#asg_instance_refresh">Figure 23</a>.</p>

</div>

<div id="asg_instance_refresh" class="imageblock">

<div class="content">

<img src="images/ch3/asg-instance-refresh.png" alt="Using the EC2 console to see an ASG instance refresh in progress">

</div>

<div class="title">Figure 23. Using the EC2 console to see an ASG instance refresh in progress</div>

</div>

<div class="paragraph">

<p>During this process, the ASG will launch three new EC2 instances, and the ALB will start performing health checks. Once

the new instances start to pass health checks, the ASG will undeploy the old one instances, leaving you with just the

three new instances running the new code. The whole process should take around five minutes.</p>

</div>

<div class="paragraph">

<p>During this deployment, the load balancer URL should always return a successful response, as this is a zero-downtime

deployment. You can even check this by opening a new terminal tab, and running the following Bash one-liner:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ while true; do curl http://&lt;load_balancer_url&gt;; sleep 1; done</pre>

</div>

</div>

<div class="paragraph">

<p>This code runs <code>curl</code>, an HTTP client, in a loop, hitting your ALB once per second and allowing you to see the

zero-downtime deployment in action. For the first couple minutes, you should see only responses from the old instances:

"Hello, World!" Then, as new instances start to pass health checks, the ALB will begin sending traffic to them, and you

should see the response from the ALB alternate between "Hello, World!" and "Fundamentals of DevOps!" After another couple

minutes, the "Hello, World!" message will disappear, and you&#8217;ll see only "Fundamentals of DevOps!", which means all the

old instances have been shut down. The output will look something like this:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>Hello, World!

Hello, World!

Hello, World!

Hello, World!

Hello, World!

Hello, World!

Fundamentals of DevOps!

Hello, World!

Fundamentals of DevOps!

Hello, World!

Fundamentals of DevOps!

Hello, World!

Fundamentals of DevOps!

Hello, World!

Fundamentals of DevOps!

Hello, World!

Fundamentals of DevOps!

Fundamentals of DevOps!

Fundamentals of DevOps!

Fundamentals of DevOps!

Fundamentals of DevOps!

Fundamentals of DevOps!</pre>

</div>

</div>

<div class="paragraph">

<p>Congrats, you&#8217;ve now seen VM orchestration in action, including rolling out changes following immutable infrastructure

practices!</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Get your hands dirty</div>

<div class="paragraph">

<p>Here are a few exercises you can try at home to get a better feel for using OpenTofu for VM orchestration:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>If you wanted to add a fourth EC2 instance to run your apps, what changes would you have to make to

the OpenTofu code? How does this compare to adding a fourth EC2 instance to the Ansible code?</p>

</li>

<li>

<p>Try restarting one of the EC2 instances using the AWS Console. How does the ALB handle it while the instance is

rebooting? Does the sample-app still work after the reboot? How does this compare to the behavior you saw when

restarting an instance with Ansible?</p>

</li>

<li>

<p>Try terminating one of the EC2 instances using the AWS Console. How does the ALB handle it? Do you need to do

anything to restore the instance?</p>

</li>

</ul>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>When you&#8217;re done experimenting with the ASG, run <code>tofu destroy</code> to undeploy all your infrastructure. This ensures that

your account doesn&#8217;t start accumulating any unwanted charges.</p>

</div>

</div>

</div>

</div>

<div class="sect2">

<h2 id="_container_orchestration">Container orchestration</h2>

<div class="paragraph">

<p>I first mentioned containers back in <a href="03.html#server_templating_tools">Section 2.3.3</a>, introducing them as essentially a lightweight

alternative to VMs. The idea with <em>container orchestration</em> is to do the following:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Create container images that have your apps and all their dependencies fully installed and configured.</p>

</li>

<li>

<p>Deploy the container images across a cluster of servers, with potentially multiple containers per server, packed in

as efficiently as possible (bin packing).</p>

</li>

<li>

<p>Automatically scale the number of servers or the number of containers up or down depending on load.</p>

</li>

<li>

<p>When you need to deploy an update, create new container images, deploy them into the cluster, and then undeploy the

old containers.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>Although containers have been around for decades<sup class="footnote">[<a id="_footnoteref_14" class="footnote" href="13-footnotes.html#_footnotedef_14" title="View footnote.">14</a>]</sup>, container orchestration started to explode in popularity

around 2013, with the emergence of Docker, a tool for building, running, and sharing containers, and

Kubernetes, a container orchestration tool. The reason for this popularity is that containers and container

orchestration offer a number of advantages over VMs and VM orchestration:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Speed</dt>

<dd>

<p>Containers typically build faster than VMs, especially with caching. Moreover, container orchestration tools

typically deploy containers faster than VMs. So the build &amp; deploy cycle with containers can be considerably

faster: you can expect 10-20 minutes for VMs, but just 1-5 minutes for containers.</p>

</dd>

<dt class="hdlist1">Efficiency</dt>

<dd>

<p>Most container orchestration tools have a built-in scheduler to decide which servers in your cluster

should run which containers, using bin packing algorithms to use the available resources as efficiently as

possible.<sup class="footnote">[<a id="_footnoteref_15" class="footnote" href="13-footnotes.html#_footnotedef_15" title="View footnote.">15</a>]</sup></p>

</dd>

<dt class="hdlist1">Portability</dt>

<dd>

<p>You can run containers and container orchestration tools everywhere, including on-prem and in all the

major cloud providers. Moreover, the most popular container tool, Docker, and container orchestration tool,

Kubernetes, are both open source. All of this means that using containers reduces lock-in to any single vendor.</p>

</dd>

<dt class="hdlist1">Local development</dt>

<dd>

<p>You can also run containers and container orchestration tools in your own local dev environment,

as containers typically have reasonable file sizes, boot quickly, and have little CPU/memory overhead. This is a huge

boon to local development, as you could now realistically run your entire tech stack—e.g., Kubernetes and Docker

containers for multiple services—completely locally. While it&#8217;s possible to run VMs locally too, VM images tend to be

considerably bigger, slower to boot, and have more CPU and memory overhead, so using them for local development is

relatively uncommon; moreover, there is no practical way to run most VM orchestration tools locally: e.g., there&#8217;s no

way to deploy an AWS ASG on your own computer.</p>

</dd>

<dt class="hdlist1">Functionality</dt>

<dd>

<p>Container orchestration tools solved more orchestration problems out-of-the-box than VM

orchestration tools. For example, Kubernetes has built-in solutions for deployment, updates, auto scaling, auto

healing, configuration, secrets management, service discovery, and disk management.</p>

</dd>

</dl>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Key takeaway #3</div>

<div class="paragraph">

<p>Container orchestration is an immutable infrastructure approach where you deploy and manage container images across a

cluster of servers.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="sect3">

<h3 id="_an_example_of_container_orchestration">An example of container orchestration</h3>

<div class="paragraph">

<p>There are many container tools out there, including <a href="https://www.docker.com/">Docker</a>,

<a href="https://github.com/moby/moby">Moby</a>, <a href="https://cri-o.io/">CRI-O</a>, <a href="https://podman.io/">Podman</a>,

<a href="https://github.com/opencontainers/runc">runc</a>, and <a href="https://github.com/moby/buildkit?tab=readme-ov-file">buildkit</a>.

Likewise, there are many container orchestration tools out there, including <a href="https://kubernetes.io/">Kubernetes</a>,

<a href="https://www.nomadproject.io/">Nomad</a>, <a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a>,

<a href="https://aws.amazon.com/ecs/">Amazon ECS</a>, <a href="https://mesosphere.github.io/marathon/">Marathon</a> /

<a href="https://mesos.apache.org/">Mesos</a>, and <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift">OpenShift</a>.

The most popular by far are Docker and Kubernetes—so much so their names are nearly synonymous with containers and

container orchestration—so that&#8217;s what we&#8217;ll focus on in this blog post series.</p>

</div>

<div class="paragraph">

<p>In the next several sections, you&#8217;ll learn to use Docker, followed by Kubernetes, and finally, you&#8217;ll learn to use

Docker and Kubernetes in AWS. Let&#8217;s get into it!</p>

</div>

<div class="sect4">

<h4 id="example_docker_crash_course">Example: a crash course on Docker</h4>

<div class="paragraph">

<p>As you may remember from <a href="03.html#server_templating_tools">Section 2.3.3</a>, Docker images are like self-contained "snapshots" of the operating

system (OS), the software, the files, and all other relevant details. Let&#8217;s now see Docker in action.</p>

</div>

<div class="paragraph">

<p>First, if you don&#8217;t have Docker installed already, follow the instructions on the

<a href="https://docs.docker.com/get-docker/">Docker website</a> to install Docker Desktop for your operating system. Once it&#8217;s

installed, you should have the <code>docker</code> command available on your command line. You can use the <code>docker run</code> command to

run Docker images locally:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker run &lt;IMAGE&gt; [COMMAND]</pre>

</div>

</div>

<div class="paragraph">

<p>where <code>IMAGE</code> is the Docker image to run and <code>COMMAND</code> is an optional command to execute. For example, here&#8217;s how you

can run a Bash shell in an Ubuntu 24.04 Docker image (note that the following command includes the <code>-it</code> flag so you

get an interactive shell where you can type):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker run -it ubuntu:24.04 bash



Unable to find image 'ubuntu:24.04' locally

24.04: Pulling from library/ubuntu

Digest: sha256:3f85b7caad41a95462cf5b787d8a04604c

Status: Downloaded newer image for ubuntu:24.04



root@d96ad3779966:/#</pre>

</div>

</div>

<div class="paragraph">

<p>And voilà, you&#8217;re now in Ubuntu! If you&#8217;ve never used Docker before, this can seem fairly magical. Try running some

commands. For example, you can look at the contents of <em>/etc/os-release</em> to verify you really are in Ubuntu:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>root@d96ad3779966:/# cat /etc/os-release

PRETTY_NAME="Ubuntu 24.04 LTS"

NAME="Ubuntu"

VERSION_ID="24.04"

(...)</pre>

</div>

</div>

<div class="paragraph">

<p>How did this happen? Well, first, Docker searches your local filesystem for the <code>ubuntu:20.04</code> image. If you don&#8217;t

have that image downloaded already, Docker downloads it automatically from <a href="https://hub.docker.com/">Docker Hub</a>, which

is a <em>Docker Registry</em> that contains shared Docker images. The <code>ubuntu:24.04</code> image happens to be a public Docker

image—an official one maintained by the Docker team—so you&#8217;re able to download it without any authentication. It&#8217;s also

possible to create private Docker images that only certain authenticated users can use, as you&#8217;ll see later in this

blog post.</p>

</div>

<div class="paragraph">

<p>Once the image is downloaded, Docker runs the image, executing the <code>bash</code> command, which starts an interactive Bash

prompt, where you can type. Try running the <code>ls</code> command to see the list of files:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>root@d96ad3779966:/# ls -al

total 56

drwxr-xr-x   1 root root 4096 Feb 22 14:22 .

drwxr-xr-x   1 root root 4096 Feb 22 14:22 ..

lrwxrwxrwx   1 root root    7 Jan 13 16:59 bin -&gt; usr/bin

drwxr-xr-x   2 root root 4096 Apr 15  2020 boot

drwxr-xr-x   5 root root  360 Feb 22 14:22 dev

drwxr-xr-x   1 root root 4096 Feb 22 14:22 etc

drwxr-xr-x   2 root root 4096 Apr 15  2020 home

lrwxrwxrwx   1 root root    7 Jan 13 16:59 lib -&gt; usr/lib

drwxr-xr-x   2 root root 4096 Jan 13 16:59 media

(...)</pre>

</div>

</div>

<div class="paragraph">

<p>You might notice that&#8217;s not your filesystem. That&#8217;s because Docker images run in containers that are isolated at the

userspace level: when you&#8217;re in a container, you can only see the filesystem, memory, networking, etc., in that

container. Any data in other containers, or on the underlying host operating system, is not accessible to you, and any

data in your container is not visible to those other containers or the underlying host operating system. This is one of

the things that makes Docker useful for running applications: the image format is self-contained, so Docker images run

the same way no matter where you run them, and no matter what else is running there.</p>

</div>

<div class="paragraph">

<p>To see this in action, write some text to a <em>test.txt</em> file as follows:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>root@d96ad3779966:/# echo "Hello, World!" &gt; test.txt</pre>

</div>

</div>

<div class="paragraph">

<p>Next, exit the container by hitting Ctrl-D on Windows and Linux or Cmd-D on macOS, and you should be back in your

original command prompt on your underlying host OS. If you try to look for the <em>test.txt</em> file you just wrote, you&#8217;ll

see that it doesn&#8217;t exist: the container&#8217;s filesystem is totally isolated from your host OS.</p>

</div>

<div class="paragraph">

<p>Now, try running the same Docker image again:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker run -it ubuntu:24.04 bash

root@3e0081565a5d:/#</pre>

</div>

</div>

<div class="paragraph">

<p>Notice that this time, since the <code>ubuntu:24.04</code> image is already downloaded, the container starts almost instantly.

This is another reason Docker is useful for running applications: unlike virtual machines, containers are lightweight,

boot up quickly, and incur little CPU or memory overhead.</p>

</div>

<div class="paragraph">

<p>You may also notice that the second time you fired up the container, the command prompt looked different. That&#8217;s

because you&#8217;re now in a totally new container; any data you wrote in the previous one is no longer accessible to you.

Run <code>ls -al</code> and you&#8217;ll see that the <em>test.txt</em> file does not exist. Containers are isolated not only from the host OS

but also from each other.</p>

</div>

<div class="paragraph">

<p>Hit Ctrl-D or Cmd-D again to exit the container, and back on your host OS, run the <code>docker ps -a</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker ps -a

CONTAINER ID   IMAGE            COMMAND    CREATED          STATUS

3e0081565a5d   ubuntu:24.04     "bash"     5 min ago    Exited (0) 16 sec ago

d96ad3779966   ubuntu:24.04     "bash"     14 min ago   Exited (0) 5 min ago</pre>

</div>

</div>

<div class="paragraph">

<p>This will show you all the containers on your system, including the stopped ones (the ones you exited). You can start

a stopped container again by using the <code>docker start &lt;ID&gt;</code> command, setting <code>ID</code> to an ID from the <code>CONTAINER ID</code> column

of the <code>docker ps</code> output. For example, here is how you can start the first container up again (and attach an

interactive prompt to it via the <code>-ia</code> flags):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker start -ia d96ad3779966

root@d96ad3779966:/#</pre>

</div>

</div>

<div class="paragraph">

<p>You can confirm this is really the first container by outputting the contents of <em>test.txt</em>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>root@d96ad3779966:/# cat test.txt

Hello, World!</pre>

</div>

</div>

<div class="paragraph">

<p>Let&#8217;s now see how a container can be used to run a web app: in particular, the Node.js sample app you&#8217;ve been using

throughout this blog post series. Hit Ctrl-D or Cmd-D again to exit the container, and back on your host OS, create a

new folder called <em>docker</em>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/docker

$ cd ch3/docker</pre>

</div>

</div>

<div class="paragraph">

<p>You should also copy <em>app.js</em> (note: you do <em>not</em> need to copy <em>app.config.js</em> this time) from the server orchestration

section into the <em>docker</em> folder:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cp ../ansible/roles/sample-app/files/app.js .</pre>

</div>

</div>

<div class="paragraph">

<p>In the <em>docker</em> folder, create a file called <em>Dockerfile</em>, with the contents shown in <a href="04.html#example_dockerfile">Example 49</a>:</p>

</div>

<div id="example_dockerfile" class="exampleblock">

<div class="title">Example 49. Dockerfile for the Node.js sample-app (<em>ch3/docker/Dockerfile</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="dockerfile"># <b class="conum">(1)</b>

FROM node:21.7



# <b class="conum">(2)</b>

WORKDIR /home/node/app



# <b class="conum">(3)</b>

COPY app.js .



# <b class="conum">(4)</b>

EXPOSE 8080



# <b class="conum">(5)</b>

USER node



# <b class="conum">(6)</b>

CMD [&quot;node&quot;, &quot;app.js&quot;]</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Just as you used a Packer template to define how to build a VM image for your sample app, this <em>Dockerfile</em> is a

template that defines how to build a Docker image for your sample app. This <em>Dockerfile</em> does the following:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>It starts with the <a href="https://hub.docker.com/_/node">official Node.js Docker image from Docker Hub</a> as the base. One

of the advantages of Docker is that it&#8217;s easy to share Docker images, so instead of having to figure out how to

install Node.js yourself, you can use the official image, which is maintained by the Node.js team.</p>

</li>

<li>

<p>Set the working directory for the rest of the build.</p>

</li>

<li>

<p>The <code>COPY</code> command copies <em>app.js</em> into the Docker image.</p>

</li>

<li>

<p>This tells the Docker image to advertise that the app within it will listen on port 8080. When someone uses your

Docker image, they can use the information from <code>EXPOSE</code> to figure out which ports they wish to expose. You&#8217;ll see

an example of this shortly.</p>

</li>

<li>

<p>Use the <code>node</code> user (created as part of the official Node.js Docker image) instead of the <code>root</code> user when running

this app.</p>

</li>

<li>

<p>When you run the Docker image, this will be the default command that it executes. Note that you typically do <em>not</em>

need to use a process supervisor for Docker images, as Docker orchestration tools take care of process supervision,

resource usage (e.g., CPU, memory), and so on, automatically. Also note that just about all container

orchestration tools expect your containers to run apps in the "foreground," blocking until they exit, and logging

directly to <code>stdout</code> and <code>stderr</code>.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>To build a Docker image from this <em>Dockerfile</em>, use the <code>docker build</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker build -t sample-app:v1 .</pre>

</div>

</div>

<div class="paragraph">

<p>The <code>-t</code> flag is the tag (name) to use for the Docker image: the preceding code sets the image name to "sample-app" and

the version to "v1." Later on, if you make changes to the sample app, you&#8217;ll be able to build a new Docker image and

give it a new version, such as "v2." The dot (<code>.</code>) at the end tells <code>docker build</code> to run the build in the current

directory (which should be the folder that contains your <em>Dockerfile</em>). When the build finishes, you can use the

<code>docker run</code> command to run your new image:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker run --init sample-app:v1

 Listening on port 8080</pre>

</div>

</div>

<div class="paragraph">

<p>Note the use of <code>--init</code>: Node.js doesn&#8217;t handle kernel signals (such as Ctrl+C) properly, so this is necessary to

ensure that the app will exit correctly if you hit Ctrl+C. See

<a href="https://github.com/nodejs/docker-node/blob/main/docs/BestPractices.md#docker-and-nodejs-best-practices">Docker and

Node.js best practices</a> for more information, including other practices that you should use with Node.js Docker images.</p>

</div>

<div class="paragraph">

<p>Your app is now listening on port 8080! However, if you open a new terminal on your host operating system and try to

access the sample app, it won&#8217;t work:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ curl localhost:8080

curl: (7) Failed to connect to localhost port 8080: Connection refused</pre>

</div>

</div>

<div class="paragraph">

<p>What&#8217;s the problem? Actually, it&#8217;s not a problem but a feature! Docker containers are isolated from the host operating

system and other containers, not only at the filesystem level but also in terms of networking. So while the container

really is listening on port 8080, that is only on a port <em>inside</em> the container, which isn&#8217;t accessible on the host OS.

If you want to expose a port from the container on the host OS, you have to do it via the <code>-p</code> flag.</p>

</div>

<div class="paragraph">

<p>First, hit Ctrl-C to shut down the sample-app container: note that it&#8217;s C this time, not D, and it&#8217;s Ctrl

regardless of OS, as you&#8217;re shutting down a process, rather than exiting an interactive prompt. Now rerun the

container but this time with the <code>-p</code> flag as follows:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker run -p 8080:8080 --init sample-app:v1

 Listening on port 8080</pre>

</div>

</div>

<div class="paragraph">

<p>Adding <code>-p 8080:8080</code> to the command tells Docker to expose port 8080 inside the container on port 8080 of the host OS.

You know to use port 8080 here, as you built this Docker image yourself, but if this was someone else&#8217;s image, you

could use <code>docker inspect</code> on the image, and that will tell you about any ports that image labeled with <code>EXPOSE</code>.

In another terminal on your host OS, you should now be able to see the sample app working:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ curl localhost:8080

Hello, World!</pre>

</div>

</div>

<div class="paragraph">

<p>Congrats, you now know how to run a web app locally using Docker! However, while using <code>docker run</code> directly is fine

for local testing and learning, it&#8217;s not the way you&#8217;d run Dockerized apps in production. For that, you typically want

to use a container orchestration tool such as Kubernetes, which is the topic of the next section.</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Cleaning Up Containers</div>

<div class="paragraph">

<p>Every time you run <code>docker run</code> and exit, you are leaving behind containers, which take up disk space. You may wish to

clean them up with the <code>docker rm &lt;CONTAINER_ID&gt;</code> command, where <code>CONTAINER_ID</code> is the ID of the container from the

<code>docker ps</code> output. Alternatively, you could include the <code>--rm</code> flag in your <code>docker run</code> command to have Docker

automatically clean up when you exit the container.</p>

</div>

</td>

</tr>

</table>

</div>

</div>

<div class="sect4">

<h4 id="example_kubernetes">Example: a crash course on Kubernetes</h4>

<div class="paragraph">

<p>Kubernetes is a container orchestration tool, which means it&#8217;s a platform for running and managing containers

on your servers, including scheduling (picking which servers should run a given container workload), auto healing

(automatically redeploying containers that failed), auto scaling (scaling the number of containers up and down in

response to load), load balancing (distributing traffic across containers), and much more.</p>

</div>

<div class="paragraph">

<p>Under the hood, Kubernetes consists of two main pieces, as shown in <a href="04.html#kubernetes_architecture">Figure 24</a>:</p>

</div>

<div id="kubernetes_architecture" class="imageblock">

<div class="content">

<img src="images/ch3/kubernetes_architecture.png" alt="The Kubernetes architecture consists of a control plane and worker nodes">

</div>

<div class="title">Figure 24. The Kubernetes architecture consists of a control plane and worker nodes</div>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">Control plane</dt>

<dd>

<p>The control plane is responsible for managing the Kubernetes cluster. It is the "brains" of the operation, responsible

for storing the state of the cluster, monitoring containers, and coordinating actions across the cluster. It also

runs the <em>API server</em>, which provides an API you can use from command-line tools (e.g., <code>kubectl</code>), web UIs (e.g., the

Kubernetes Dashboard), and IaC tools (e.g., OpenTofu) to control what&#8217;s happening in the cluster.</p>

</dd>

<dt class="hdlist1">Worker nodes</dt>

<dd>

<p>The worker nodes are the servers used to actually run your containers. The worker nodes are entirely managed by the

control plane, which tells each worker node what containers it should run.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>Kubernetes is open source, and one of its strengths is that you can run it anywhere: in any public cloud (e.g., AWS,

Azure, GCP), in your own datacenter, and even on your personal computer. A little later in this

blog post, I&#8217;ll show you how you can run Kubernetes in the cloud (in AWS), but for now, let&#8217;s start

small and run it locally. This is easy to do if you installed a relatively recent version of Docker Desktop, as it has

the ability to fire up a Kubernetes cluster locally with just a few clicks.</p>

</div>

<div class="paragraph">

<p>If you open Docker Desktop&#8217;s preferences on your computer, you should see Kubernetes in the nav, as shown in

<a href="04.html#docker_desktop_k8s">Figure 25</a>.</p>

</div>

<div id="docker_desktop_k8s" class="imageblock">

<div class="content">

<img src="images/ch3/docker-desktop-k8s.png" alt="Enable Kubernetes on Docker Desktop">

</div>

<div class="title">Figure 25. Enable Kubernetes on Docker Desktop.</div>

</div>

<div class="paragraph">

<p>If it&#8217;s not enabled already, check the Enable Kubernetes checkbox, click Apply &amp; Restart, and wait a few minutes

for that to complete. In the meantime, follow the instructions on the

<a href="https://kubernetes.io/docs/tasks/tools/">Kubernetes website</a> to install <code>kubectl</code>, which is the command-line tool for

interacting with Kubernetes.</p>

</div>

<div class="paragraph">

<p>To use <code>kubectl</code>, you must first update its configuration file, which lives in <em>$HOME/.kube/config</em> (that is, the

<em>.kube</em> folder of your home directory), to tell it what Kubernetes cluster to connect to. Conveniently, when you enable

Kubernetes in Docker Desktop, it updates this config file for you, adding a <code>docker-desktop</code> entry to it, so all you

need to do is tell <code>kubectl</code> to use this configuration as follows:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl config use-context docker-desktop

Switched to context "docker-desktop".</pre>

</div>

</div>

<div class="paragraph">

<p>Now you can check if your Kubernetes cluster is working with the <code>get nodes</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get nodes

NAME             STATUS   ROLES           AGE     VERSION

docker-desktop   Ready    control-plane   2m31s   v1.29.1</pre>

</div>

</div>

<div class="paragraph">

<p>The <code>get nodes</code> command shows you information about all the nodes in your cluster. Since you&#8217;re running Kubernetes

locally, your computer is the only node, and it&#8217;s running both the control plane and acting as a worker node. You&#8217;re

now ready to run some Docker containers!</p>

</div>

<div class="paragraph">

<p>To deploy something in Kubernetes, you create Kubernetes <em>objects</em>, which are persistent entities you write to the

Kubernetes cluster (via the API server) that record your intent: e.g., your intent to have specific Docker images

running. The cluster runs a <em>reconciliation loop</em>, which continuously checks the objects you stored in it and works to

make the state of the cluster match your intent.</p>

</div>

<div class="paragraph">

<p>There are many different types of Kubernetes objects available. The one we&#8217;ll use to deploy your sample app is a

<em>Kubernetes Deployment</em>, which is a declarative way to manage an application in Kubernetes. The Deployment allows you

to declare what Docker images to run, how many copies of them to run (called <em>replicas</em>), a variety of settings for

those images (e.g., CPU, memory, port numbers, environment variables), and so on, and the Deployment will then work to

ensure that the requirements you declared are always met.</p>

</div>

<div class="paragraph">

<p>One way to interact with Kubernetes is to create YAML files describing what you want and to use the

<code>kubectl apply</code> command to submit those objects to the cluster. Create a new folder called <em>kubernetes</em> to store these

YAML files:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/kubernetes

$ cd ch3/kubernetes</pre>

</div>

</div>

<div class="paragraph">

<p>Within the <em>kubernetes</em> folder, create a file called <em>sample-app-deployment.yml</em> with the contents shown in

<a href="04.html#example_kubernetes_deployment_yaml">Example 50</a>:</p>

</div>

<div id="example_kubernetes_deployment_yaml" class="exampleblock">

<div class="title">Example 50. The YAML for a Kubernetes Deployment (<em>ch3/kubernetes/sample-app-deployment.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">apiVersion</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">apps/v1</span></span>

<span style="color:#606">kind</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">Deployment                  </span></span># <b class="conum">(1)</b>

<span style="color:#606">metadata</span>:                         # <b class="conum">(2)</b>

  <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app-deployment</span></span>

<span style="color:#606">spec</span>:

  <span style="color:#606">replicas</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">3                     </span></span># <b class="conum">(3)</b>

  <span style="color:#606">template</span>:                       # <b class="conum">(4)</b>

    <span style="color:#606">metadata</span>:                     # <b class="conum">(5)</b>

      <span style="color:#606">labels</span>:

        <span style="color:#606">app</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app-pods</span></span>

    <span style="color:#606">spec</span>:

      <span style="color:#606">containers</span>:                 # <b class="conum">(6)</b>

        - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: sample-app        </span></span># <b class="conum">(7)</b>

          <span style="color:#606">image</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app:v1    </span></span># <b class="conum">(8)</b>

          <span style="color:#606">ports</span>:

            - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">containerPort: 8080 </span></span># <b class="conum">(9)</b>

          <span style="color:#606">env</span>:                    # <b class="conum">(10)</b>

            - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: NODE_ENV</span></span>

              <span style="color:#606">value</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">production</span></span>

  <span style="color:#606">selector</span>:                       # <b class="conum">(11)</b>

    <span style="color:#606">matchLabels</span>:

      <span style="color:#606">app</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app-pods</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This YAML file gives you a lot of functionality for just ~20 lines of code:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>The <code>kind</code> keyword specifies that this is Kubernetes object is a Deployment.</p>

</li>

<li>

<p>Every Kubernetes object includes metadata that can be used to identify and target that object in API calls.

Kubernetes makes heavy use of metadata and labels to keep the system highly flexible and loosely coupled. The

preceding code sets the name of the Deployment to "sample-app-deployment."</p>

</li>

<li>

<p>The Deployment will run 3 replicas.</p>

</li>

<li>

<p>This is the <em>pod template</em>—the blueprint—that defines what this Deployment will deploy and manage. It&#8217;s similar to

the launch template you saw with AWS ASGs. In Kubernetes, instead of deploying one container at a time, you deploy

<em>pods</em>, which are groups of containers that are meant to be deployed together. For example, you could have a pod

with one container to run a web app (e.g., the sample app) and another container that gathers metrics on the web

app and sends them to a central service (e.g., Datadog). So this <code>template</code> block allows you to configure your

pods, specifying what container(s) to run, the ports to use, environment variables to set, and so on.</p>

</li>

<li>

<p>Templates can be used separate from Deployments, so they have separate metadata which allows you to identify and

target that template in API calls (this is another example of Kubernetes trying to be highly flexible and

decoupled). The preceding code sets the "app" label to "sample-app-pods." You&#8217;ll see how this is used shortly.</p>

</li>

<li>

<p>Inside the pod template, you define one or more containers to run in that pod.</p>

</li>

<li>

<p>This simple example configures just a single container to run, giving it the name "sample-app."</p>

</li>

<li>

<p>The Docker image to run for this container. This is the Docker image you built earlier in the

post.</p>

</li>

<li>

<p>This tells Kubernetes that the Docker image listens for requests on port 8080.</p>

</li>

<li>

<p>The <code>env</code> configuration lets you set environment variables for the container. The preceding code sets the

<code>NODE_ENV</code> environment variable to "production" to tell the Node.js app and all its dependencies to run in

production mode.</p>

</li>

<li>

<p>The <code>selector</code> block tells the Kubernetes Deployment what to target: that is, which pod template to deploy

and manage. Why doesn&#8217;t the Deployment just assume that the pod defined within that Deployment is the one you want

to target? Because Deployments and templates can be defined completely separately, so you always need to specify a

<code>selector</code> to tell the Deployment what to target (this is yet another example of Kubernetes trying to be

flexible and decoupled).</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>You can use the <code>kubectl apply</code> command to apply your Deployment configuration:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl apply -f sample-app-deployment.yml

deployment.apps/sample-app-deployment created</pre>

</div>

</div>

<div class="paragraph">

<p>This command should complete very quickly. How do you know if it actually worked? To answer that question, you can

use <code>kubectl</code> to explore your cluster. First, run the <code>get deployments</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get deployments

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE

sample-app-deployment   3/3     3            3           1m</pre>

</div>

</div>

<div class="paragraph">

<p>Here, you can see how Kubernetes uses metadata, as the name of the deployment (sample-app-deployment) comes from your

<code>metadata</code> block. You can use that metadata in API calls yourself. For example, to get more details about a specific

Deployment, you can run <code>describe deployment &lt;NAME&gt;</code>, where <code>&lt;NAME&gt;</code> is the name from the metadata:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl describe deployment sample-app-deployment

Name:                   sample-app-deployment

CreationTimestamp:      Mon, 15 Apr 2024 12:28:19 -0400

Selector:               app=sample-app-pods

Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable

StrategyType:           RollingUpdate

MinReadySeconds:        0

RollingUpdateStrategy:  0 max unavailable, 3 max surge

(... truncated for readability ...)</pre>

</div>

</div>

<div class="paragraph">

<p>This Deployment is reporting that all 3 replicas are available. To see those replicas, run the <code>get pods</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get pods

NAME                                     READY   STATUS    RESTARTS   AGE

sample-app-deployment-64f97797fb-hcskq   1/1     Running   0          4m23s

sample-app-deployment-64f97797fb-p7zjk   1/1     Running   0          4m23s

sample-app-deployment-64f97797fb-qtkl8   1/1     Running   0          4m23s</pre>

</div>

</div>

<div class="paragraph">

<p>And to get the details about a specific pod, copy its name, and run <code>describe pod</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl describe pod sample-app-deployment-64f97797fb-hcskq

Name:             sample-app-deployment-64f97797fb-hcskq

Node:             docker-desktop/192.168.65.3

Start Time:       Mon, 15 Apr 2024 14:08:04 -0400

Labels:           app=sample-app-pods

                  pod-template-hash=64f97797fb

Status:           Running

IP:               10.1.0.31

Controlled By:  ReplicaSet/sample-app-deployment-64f97797fb

Containers:

  sample-app:

    Image:          sample-app:v1

    Port:           8080/TCP

    Host Port:      0/TCP

(... truncated for readability ...)</pre>

</div>

</div>

<div class="paragraph">

<p>From this output, you can see the containers that are running for each pod, which in this case, is just one container

per pod running the sample-app:v1 Docker image you built earlier.</p>

</div>

<div class="paragraph">

<p>You can also see the logs for a single pod by using the <code>logs</code> command, which is useful for understanding what&#8217;s going

on and debugging:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl logs sample-app-deployment-64f97797fb-hcskq

Listening on port 8080</pre>

</div>

</div>

<div class="paragraph">

<p>Ah, there&#8217;s that familiar log output. You now have three replicas of your sample app running. But, just as you saw with

server and VM orchestration, users will want just one endpoint to hit, so now it&#8217;s time to figure out how to do load

balancing with Kubernetes.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_load_balancing_with_kubernetes">Example: load balancing with Kubernetes</h4>

<div class="paragraph">

<p>Kubernetes has built-in support for load balancing. The typical way to set it up is to make use of another Kubernetes

object, called a  <em>Kubernetes Service</em>, which is a way to expose an app running in Kubernetes as a service you can

talk to over the network. <a href="04.html#example_kubernetes_service_yaml">Example 51</a> shows the YAML code for a Kubernetes service, which you

should put in a file called <em>sample-app-service.yml</em>:</p>

</div>

<div id="example_kubernetes_service_yaml" class="exampleblock">

<div class="title">Example 51. The YAML for a Kubernetes Service (<em>ch3/kubernetes/sample-app-service.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">apiVersion</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">v1</span></span>

<span style="color:#606">kind</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">Service                    </span></span># <b class="conum">(1)</b>

<span style="color:#606">metadata</span>:                        # <b class="conum">(2)</b>

  <span style="color:#606">name</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app-loadbalancer</span></span>

<span style="color:#606">spec</span>:

  <span style="color:#606">type</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">LoadBalancer             </span></span># <b class="conum">(3)</b>

  <span style="color:#606">selector</span>:

    <span style="color:#606">app</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app-pods         </span></span># <b class="conum">(4)</b>

  <span style="color:#606">ports</span>:

    - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">protocol: TCP</span></span>

      <span style="color:#606">port</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">80                   </span></span># <b class="conum">(5)</b>

      <span style="color:#606">targetPort</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">8080           </span></span># <b class="conum">(6)</b></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Here&#8217;s what this code does:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p>This Kubernetes object is a Service.</p>

</li>

<li>

<p>You have to configure metadata for every Kubernetes object. The preceding code sets the name of the

Service to "sample-app-loadbalancer."</p>

</li>

<li>

<p>Configure the Service to be a load balancer.<sup class="footnote">[<a id="_footnoteref_16" class="footnote" href="13-footnotes.html#_footnotedef_16" title="View footnote.">16</a>]</sup> Under the hood, depending on what sort of Kubernetes cluster you&#8217;re running, and how you configure

that cluster, the actual type of load balancer you get will be different: for example, if you run this code in AWS,

you&#8217;ll get an AWS ELB; if you run it in GCP, you&#8217;ll get a Cloud Load Balancer; and if you run it locally, as

you will shortly, you&#8217;ll get a simple load balancer that is built into the Kubernetes distribution in Docker

Desktop.</p>

</li>

<li>

<p>Distribute traffic across the pods you defined in the Deployment.</p>

</li>

<li>

<p>The Service will receive requests on port 80, the default HTTP port.</p>

</li>

<li>

<p>The Service will forward requests to port 8080 of the pods.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>You apply the Service the same way, using <code>kubectl apply</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl apply -f sample-app-service.yml

service/sample-app-loadbalancer created</pre>

</div>

</div>

<div class="paragraph">

<p>To see if your service worked, use the <code>get services</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get services

NAME                      TYPE           CLUSTER-IP       ExTERNAL-IP   PORT(S)

kubernetes                ClusterIP      10.96.0.1        &lt;none&gt;        443/TCP

sample-app-loadbalancer   LoadBalancer   10.111.250.210   localhost     80:30910/TCP</pre>

</div>

</div>

<div class="paragraph">

<p>The first service in the list is Kubernetes itself, which you can ignore. The second is the Service you created, with

the name sample-app-loadbalancer (based on its own <code>metadata</code> block). You can get more details about your service

by using the <code>describe service</code> command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl describe service sample-app-loadbalancer

Name:                     sample-app-loadbalancer

Selector:                 app=sample-app-pods

Type:                     LoadBalancer

LoadBalancer Ingress:     localhost

Port:                     &lt;unset&gt;  80/TCP

TargetPort:               8080/TCP

(... truncated for readability ...)</pre>

</div>

</div>

<div class="paragraph">

<p>You can see that the load balancer is listening on localhost, at port 80, so you can test it out by opening

<a href="http://localhost" class="bare">http://localhost</a> in your browser, or using <code>curl</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ curl http://localhost

Hello, World!</pre>

</div>

</div>

<div class="paragraph">

<p>Congrats! You&#8217;re now able to deploy Docker containers with Kubernetes and distribute traffic across your containers

with a load balancer. But what if you want to update your app?</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_rolling_out_updates_with_kubernetes">Example: rolling out updates with Kubernetes</h4>

<div class="paragraph">

<p>Kubernetes Deployments have built-in support for rolling updates. Open up <em>sample-app-deployment.yml</em> and add the

code shown in <a href="04.html#example_kubernetes_deployment_update">Example 52</a> to the bottom of the <code>spec</code> section:</p>

</div>

<div id="example_kubernetes_deployment_update" class="exampleblock">

<div class="title">Example 52. The YAML for doing rolling updates (<em>ch3/kubernetes/sample-app-deployment.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">spec</span>:



  <span style="color:#777"># (... other params omitted for clarity ...)</span>



  <span style="color:#606">strategy</span>:

    <span style="color:#606">type</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">RollingUpdate</span></span>

    <span style="color:#606">rollingUpdate</span>:

      <span style="color:#606">maxSurge</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">3</span></span>

      <span style="color:#606">maxUnavailable</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">0</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This configures the Deployment to do a rolling update where it can deploy up to 3 extra pods during the deployment,

similar to the instance refresh you saw with ASGs. Run <code>apply</code> to update the Deployment with these changes:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl apply -f sample-app-deployment.yml

deployment.apps/sample-app-deployment configured</pre>

</div>

</div>

<div class="paragraph">

<p>Now, make a change to the sample app in <em>docker/app.js</em>, such as returning the text "Fundamentals of DevOps!" instead of

"Hello, World!", as shown in <a href="04.html#example_kubernetes_updated_response">Example 53</a>:</p>

</div>

<div id="example_kubernetes_updated_response" class="exampleblock">

<div class="title">Example 53. Update the app to respond with the text "Fundamentals of DevOps!" (<em>ch3/docker/app.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">  res.end(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">Fundamentals of DevOps!</span><span style="color:#D20">\n</span><span style="color:#710">'</span></span>);</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>To deploy this change, the first step is to build a new Docker image, with <code>v2</code> as the new version:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker build -t sample-app:v2 .</pre>

</div>

</div>

<div class="paragraph">

<p>The build will likely run in less than a second! This is because Docker has a built-in

<a href="https://docs.docker.com/build/cache/">build cache</a>, which, if used correctly, can dramatically speed up builds.</p>

</div>

<div class="paragraph">

<p>Next, open <em>sample-app-deployment.yml</em> one more time, and in the <code>spec</code> section, update the <code>image</code>

from <code>sample-app:v1</code> to <code>sample-app:v2</code>, as shown in <a href="04.html#example_kubernetes_updated_image">Example 54</a>:</p>

</div>

<div id="example_kubernetes_updated_image" class="exampleblock">

<div class="title">Example 54. Update the Deployment to use the v2 image (<em>ch3/kubernetes/sample-app-deployment.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">spec</span>:



  <span style="color:#777"># (... other params omitted for clarity ...)</span>



    <span style="color:#606">spec</span>:

      <span style="color:#606">containers</span>:

        - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: sample-app</span></span>

          <span style="color:#606">image</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">sample-app:v2</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Run <code>apply</code> one more time to deploy this change:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl apply -f sample-app-deployment.yml

deployment.apps/sample-app-deployment configured</pre>

</div>

</div>

<div class="paragraph">

<p>In the background, Kubernetes will kick off the rolling update. If you run <code>get pods</code> during this process, you&#8217;ll see

up to six pods running at the same time (three old, three new):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get pods

NAME                                     READY   STATUS    RESTARTS   AGE

sample-app-deployment-64f97797fb-pnh96   1/1     Running   0          15m

sample-app-deployment-64f97797fb-tmprp   1/1     Running   0          15m

sample-app-deployment-64f97797fb-xmjfl   1/1     Running   0          15m

sample-app-deployment-6c5ff6d6ff-fxqd4   1/1     Running   0          21s

sample-app-deployment-6c5ff6d6ff-hvwjx   1/1     Running   0          21s

sample-app-deployment-6c5ff6d6ff-krkcs   1/1     Running   0          21s</pre>

</div>

</div>

<div class="paragraph">

<p>After a little while, the three old pods will be undeployed, and you&#8217;ll be left with just the new ones. At that point,

the load balancer will be responding with "Fundamentals of DevOps!"</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ curl http://localhost

Fundamentals of DevOps!</pre>

</div>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Get your hands dirty: other ways to interact with Kubernetes</div>

<div class="paragraph">

<p>Using YAML and <code>kubectl</code> is a great way to learn Kubernetes, and I&#8217;m using it in the examples in this

blog post to avoid introducing extra tools, but raw YAML is not a great choice for production usage. In

particular, YAML doesn&#8217;t have support for variables, templating, for-loops, conditionals, and other programming

language features that allow for code reuse.</p>

</div>

<div class="paragraph">

<p>Therefore, when using Kubernetes in production, instead of raw YAML, try out one of the following tools that can solve

these gaps for you:</p>

</div>

<div class="ulist">

<ul>

<li>

<p><a href="https://helm.sh/">Helm</a></p>

</li>

<li>

<p><a href="https://opentofu.org/">OpenTofu</a> with the

<a href="https://github.com/hashicorp/terraform-provider-kubernetes">Kubernetes provider</a></p>

</li>

<li>

<p><a href="https://www.pulumi.com/">Pulumi</a> with the <a href="https://www.pulumi.com/registry/packages/kubernetes/">Kubernetes provider</a></p>

</li>

<li>

<p><a href="https://kustomize.io/">Kustomize</a></p>

</li>

<li>

<p><a href="https://carvel.dev/kapp/">kapp</a></p>

</li>

</ul>

</div>

</td>

</tr>

</table>

</div>

</div>

<div class="sect4">

<h4 id="example_docker_kubernetes_aws">Example: deploying a Kubernetes cluster in AWS</h4>

<div class="paragraph">

<p>So far, you&#8217;ve been running Kubernetes locally, which is great for learning and testing. However, for production

deployments, you&#8217;ll need to run a Kubernetes cluster on servers in a data center. Kubernetes is a complicated system:

it&#8217;s more or less a cloud in and of itself, and setting it up and maintaining it is a significant undertaking.

Fortunately, if you&#8217;re using the cloud, most cloud providers have managed Kubernetes offerings that make this

considerably simpler. The one you&#8217;ll learn to use in this blog post series is Amazon&#8217;s <em>Elastic Kubernetes Service

(EKS)</em>, which can deploy and manage the control plane and worker nodes for you.</p>

</div>

<div class="paragraph">

<p>The blog post series&#8217;s sample code repo contains a module called <code>eks-cluster</code> in the <em>ch3/tofu/modules/eks-cluster</em>

folder that you can use to deploy a simple EKS cluster, which includes the following:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>A fully-managed control plane.</p>

</li>

<li>

<p>Fully-managed worker nodes. EKS supports

<a href="https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html">several types of worker nodes</a>; the

<code>eks-cluster</code> module uses an <em>EKS managed node group</em>, which deploys worker nodes in an ASG, so you&#8217;re making use of

VM orchestration in addition to container orchestration, although the VM orchestration is mostly invisible to you, as

AWS handles all the details.</p>

</li>

<li>

<p>IAM roles with the minimal permissions required by the control plane and worker nodes. An <em>IAM role</em> is similar to an

IAM user, in that it&#8217;s an entity in AWS that can be granted IAM permissions. However, unlike IAM users, IAM roles are

not associated with any one person and do not have permanent credentials (password or access keys). Instead, a role

can be <em>assumed</em> by other IAM entities, such as the EKS control plane. So an IAM role is a mechanism for granting

those services permissions to make certain API calls in your AWS account.</p>

</li>

<li>

<p>Everything deploys into the Default VPC (see the note on Default VPCs in <a href="04.html#default_vpc">A Note on Default Virtual Private Clouds</a>).</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>To use the <code>eks-cluster</code> module, create a new folder called <em>live/eks-sample</em> to use as a root module:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/tofu/live/eks-sample

$ cd ch3/tofu/live/eks-sample</pre>

</div>

</div>

<div class="paragraph">

<p>Inside of the <em>eks-sample</em> folder, create a file called <em>main.tf</em>, with the contents shown in

<a href="04.html#example_kubernetes_tofu_module">Example 55</a>:</p>

</div>

<div id="example_kubernetes_tofu_module" class="exampleblock">

<div class="title">Example 55. Configure the <code>eks-cluster</code> module (<em>ch3/tofu/live/eks-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">provider &quot;aws&quot; {

  region = &quot;us-east-2&quot;

}



module &quot;cluster&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/eks-cluster&quot;



  name        = &quot;eks-sample&quot;        # <b class="conum">(1)</b>

  eks_version = &quot;1.29&quot;              # <b class="conum">(2)</b>



  instance_type        = &quot;t2.micro&quot; # <b class="conum">(3)</b>

  min_worker_nodes     = 1          # <b class="conum">(4)</b>

  max_worker_nodes     = 10         # <b class="conum">(5)</b>

  desired_worker_nodes = 3          # <b class="conum">(6)</b>

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code configures the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>name</code>: The name to use for the control plane, worker nodes, and all other resources created by the module.</p>

</li>

<li>

<p><code>eks_version</code>: The version of Kubernetes to use. A new version comes out roughly once per quarter.</p>

</li>

<li>

<p><code>instance_type</code>: The type of instance to run for worker nodes.</p>

</li>

<li>

<p><code>min_worker_nodes</code>: The minimum number of worker nodes to run.</p>

</li>

<li>

<p><code>max_worker_nodes</code>: The maximum number of worker nodes to run.</p>

</li>

<li>

<p><code>desired_worker_nodes</code>: The initial number of worker nodes to run.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>To deploy the EKS cluster, authenticate to AWS as described in <a href="03.html#example_authenticate_on_the_cli">Section 2.2</a>, and run the

following commands:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu init

$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p>After 3-5 minutes, the cluster should finish deploying. To explore the cluster with <code>kubectl</code>, you first need to

authenticate to your cluster. The <code>aws</code> CLI has a built-in command for doing this:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>aws eks update-kubeconfig --region &lt;REGION&gt; --name &lt;CLUSTER_NAME&gt;</pre>

</div>

</div>

<div class="paragraph">

<p>Where <code>&lt;REGION&gt;</code> is the AWS region you deployed the EKS cluster into and <code>&lt;CLUSTER_NAME&gt;</code> is the name of the EKS

cluster. If you deployed the <code>eks-cluster</code> module with default settings, these are <code>us-east-2</code> and <code>eks-tofu</code>,

respectively, so you can run the following:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>aws eks update-kubeconfig --region us-east-2 --name eks-tofu</pre>

</div>

</div>

<div class="paragraph">

<p>Once this is done, try running <code>get nodes</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get nodes

NAME                                          STATUS   ROLES    AGE

ip-172-31-21-41.us-east-2.compute.internal    Ready    &lt;none&gt;   5m

ip-172-31-34-203.us-east-2.compute.internal   Ready    &lt;none&gt;   5m

ip-172-31-4-188.us-east-2.compute.internal    Ready    &lt;none&gt;   5m</pre>

</div>

</div>

<div class="paragraph">

<p>This output looks a bit different from when you ran the command with the Kubernetes cluster from Docker Desktop. You

should see three nodes, each of which is an EC2 instance in your managed node group.</p>

</div>

<div class="paragraph">

<p>The next step is to try deploying the sample app into the EKS cluster. However, there&#8217;s one problem: you&#8217;ve created a

Docker image for the sample app, but that image only lives on your own computer. The EKS cluster in AWS won&#8217;t be able

to fetch the image from your computer, so you need to push the image to a container registry that EKS can read from, as

described in the next section.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_pushing_docker_images_to_ecr">Example: pushing Docker images to ECR</h4>

<div class="paragraph">

<p>There are a number of container registries out there, including <a href="https://hub.docker.com/">Docker Hub</a>, Amazon&#8217;s

<a href="https://aws.amazon.com/ecr/">Elastic Container Registry (ECR)</a>, the

<a href="https://azure.microsoft.com/en-us/products/container-registry">Azure Container Registry</a>, the

<a href="https://cloud.google.com/artifact-registry">Google Artifact Registry</a>, the

<a href="https://jfrog.com/integration/docker-registry/">JFrog Docker Registry</a>, and the

<a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry">GitHub

Container Registry</a>. If you&#8217;re using AWS, the easiest one to use is ECR, so let&#8217;s set that up.</p>

</div>

<div class="paragraph">

<p>For each Docker image you want to store in ECR, you have to create an <em>ECR repository</em> (<em>ECR repo</em> for short). The

blog post series&#8217;s sample code repo includes a module called <code>ecr-repo</code> in the <em>ch3/tofu/modules/ecr-repo</em> folder

that you can use to create an ECR repo.</p>

</div>

<div class="paragraph">

<p>To use the <code>ecr-repo</code> module, create a new folder called <em>live/ecr-sample</em> to use as a root module:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/tofu/live/ecr-sample

$ cd ch3/tofu/live/ecr-sample</pre>

</div>

</div>

<div class="paragraph">

<p>In the <em>ecr-sample</em> folder, create a file called <em>main.tf</em> with the contents shown in <a href="04.html#example_ecr_tofu_module">Example 56</a>:</p>

</div>

<div id="example_ecr_tofu_module" class="exampleblock">

<div class="title">Example 56. Configure the <code>ecr-repo</code> module (<em>ch3/tofu/live/ecr-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">provider &quot;aws&quot; {

  region = &quot;us-east-2&quot;

}



module &quot;repo&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/ecr-repo&quot;



  name = &quot;sample-app&quot;

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This code will create an ECR repo called "sample-app." Typically, the repo name should match your Docker image name.</p>

</div>

<div class="paragraph">

<p>You should also create <em>outputs.tf</em> with an output variable, as shown in <a href="04.html#example_ecr_tofu_module_outputs">Example 57</a>:</p>

</div>

<div id="example_ecr_tofu_module_outputs" class="exampleblock">

<div class="title">Example 57. The <code>ecr-sample</code> module output variables (<em>ch3/tofu/live/ecr-sample/outputs.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">output &quot;registry_url&quot; {

  value       = module.repo.registry_url

  description = &quot;URL of the ECR repo&quot;

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>The preceding code will output the URL of the ECR repo, which you&#8217;ll need to be able to push and pull images. To create

the ECR repo, run the following commands:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu init

$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p>After a few seconds, you should see the <code>registry_url</code> output:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>Apply complete! Resources: 1 added, 0 changed, 0 destroyed.



Outputs:



registry_url = "111111111111.dkr.ecr.us-east-2.amazonaws.com/sample-app"</pre>

</div>

</div>

<div class="paragraph">

<p>Copy down that <code>registry_url</code> value, as you&#8217;ll need it shortly.</p>

</div>

<div class="paragraph">

<p>Before you can push your Docker image to this ECR repo, you have to build the image with the right <em>CPU architecture</em>.

Each Docker image you build is built for a specific CPU architecture: the <code>docker build</code> command, by default, builds

for whatever CPU architecture you have on your own computer. For example, if you&#8217;re on a recent Macbook with an ARM

CPU (e.g., the M1 or M2), your Docker images will be built for the <code>arm64</code> architecture. This is a problem if

you try to run those Docker images in the EKS cluster deployed by the <code>eks-cluster</code> module, as the <code>t2.micro</code> worker

nodes in that cluster use the <code>amd64</code> architecture, and won&#8217;t be able to run <code>arm64</code> images.</p>

</div>

<div class="paragraph">

<p>Therefore, you need to ensure that you build your Docker images for whatever architecture(s) you plan to deploy onto.

Fortunately, Docker now ships with the <code>buildx</code> command, which makes it easy to build Docker images for multiple

architectures. The very first time you use <code>buildx</code>, you need to create a multi-platform-builder for your target

architectures. For example, if you&#8217;re on an ARM64 Mac, and you&#8217;re going to be deploying onto AMD64 Linux servers, use

the following command:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker buildx create \

  --use \

  --platform=linux/amd64,linux/arm64 \

  --name multi-platform-builder</pre>

</div>

</div>

<div class="paragraph">

<p>Now you can run the following command to build a Docker image of the sample app for both architectures (note the use of

a new tag, <code>v3</code>, for these images):</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker buildx build \

  --platform=linux/amd64,linux/arm64 \

  -t sample-app:v3 \

  .</pre>

</div>

</div>

<div class="paragraph">

<p>Once the build is done, to be able to push the Docker image to ECR, you need to tag it using the registry URL of the

ECR repo that you got from the <code>registry_url</code> output:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>docker tag \

  sample-app:v3 \

  111111111111.dkr.ecr.us-east-2.amazonaws.com/sample-app:v3</pre>

</div>

</div>

<div class="paragraph">

<p>Next, you need to authenticate to your ECR repo, which you can do using a combination of the <code>aws</code> CLI and the <code>docker</code>

CLI:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ aws ecr \

  get-login-password \

  --region us-east-2 | \

  docker login \

  --username AWS \

  --password-stdin \

  111111111111.dkr.ecr.us-east-2.amazonaws.com/sample-app</pre>

</div>

</div>

<div class="paragraph">

<p>Finally, you can push the Docker image to your ECR repo:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ docker push 111111111111.dkr.ecr.us-east-2.amazonaws.com/sample-app:v3</pre>

</div>

</div>

<div class="paragraph">

<p>The first time you push, it may take a minute or two to upload the image. Subsequent pushes, due to Docker&#8217;s layer

caching, will be faster.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_deploying_apps_into_eks">Example: deploying apps into EKS</h4>

<div class="paragraph">

<p>At this point, you are ready to deploy the sample app Docker image into the EKS cluster. The only change you need to

make to the YAML you used to deploy locally is to switch the <code>image</code> in <em>kubernetes/sample-app-deployment.yml</em> to the

<code>v3</code> ECR repo URL, as shown in <a href="04.html#example_ecr_deployment_image_update">Example 58</a>:</p>

</div>

<div id="example_ecr_deployment_image_update" class="exampleblock">

<div class="title">Example 58. Update the Deployment to use the Docker image from your ECR repo (<em>ch3/kubernetes/sample-app-deployment.yml</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="yaml"><span style="color:#606">spec</span>:



  <span style="color:#777"># (... other params omitted for clarity ...)</span>



    <span style="color:#606">spec</span>:

      <span style="color:#606">containers</span>:

        - <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">name: sample-app</span></span>

          <span style="color:#606">image</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#D20">111111111111.dkr.ecr.us-east-2.amazonaws.com/sample-app:v3</span></span></code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>You can now <code>apply</code> both YAML files to deploy into your EKS cluster:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl apply -f sample-app-deployment.yml

$ kubectl apply -f sample-app-service.yml</pre>

</div>

</div>

<div class="paragraph">

<p>Deployments to an EKS cluster will take slightly longer than a local Kubernetes cluster, but after a minute or two,

if you run the <code>get pods</code> command, you should see something like this:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ kubectl get pods

NAME                                     READY   STATUS    RESTARTS   AGE

sample-app-deployment-59f5c6cd66-nk45z   1/1     Running   0          1m

sample-app-deployment-59f5c6cd66-p5jxz   1/1     Running   0          1m

sample-app-deployment-59f5c6cd66-pmjns   1/1     Running   0          1m</pre>

</div>

</div>

<div class="paragraph">

<p>And if you run <code>get services</code>, you should see something like this:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>NAME                      TYPE          ExTERNAL-IP                       PORT(S)

kubernetes                ClusterIP     &lt;none&gt;                            443/TCP

sample-app-loadbalancer   LoadBalancer  xxx.us-east-2.elb.amazonaws.com   80:32254/TCP</pre>

</div>

</div>

<div class="paragraph">

<p>If you look at the <code>EXTERNAL-IP</code> for <code>sample-app-loadbalancer</code>, you should see the domain name of an AWS ELB! Open this

URL up in a web browser or using <code>curl</code>:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ curl xxx.us-east-2.elb.amazonaws.com

Fundamentals of DevOps!</pre>

</div>

</div>

<div class="paragraph">

<p>If you get "Could not resolve host" errors, this is probably because the load balancer is still booting up or the

health checks haven&#8217;t passed yet. Give it a minute or two more, and try again, and you should see the familiar

"Fundamentals of DevOps!" text.</p>

</div>

<div class="paragraph">

<p>Congrats, you&#8217;re now running a Dockerized application in a Kubernetes cluster in AWS!</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Get your hands dirty</div>

<div class="paragraph">

<p>Here are a few exercises you can try at home to get a better feel for using Kubernetes for container orchestration:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>By default, if you deploy a Kubernetes Service of type LoadBalancer into EKS, EKS will create a <em>Classic Load

Balancer</em>, which is an older type of load balancer that is not generally recommended anymore. In most cases, you

actually want an Application Load Balancer (ALB), as you saw in the VM orchestration section. To deploy an ALB, you

need to make a few changes, as explained in the

<a href="https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html">AWS documentation</a>.</p>

</li>

<li>

<p>Try terminating one of the worker node EC2 instances using the AWS Console. How does the ELB handle it? How does EKS

respond? Do you need to do anything to restore the instance or your containers?</p>

</li>

<li>

<p>Try using <code>kubectl exec</code> to get a shell (like an SSH session) into a running container.</p>

</li>

</ul>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>When you&#8217;re done experimenting with the EKS cluster, run <code>tofu destroy</code> on both the <code>eks-cluster</code> and <code>ecr-repo</code>

modules to undeploy all your infrastructure. This ensures that your account doesn&#8217;t start accumulating any unwanted

charges.</p>

</div>

</div>

</div>

</div>

<div class="sect2">

<h2 id="_serverless_orchestration">Serverless orchestration</h2>

<div class="paragraph">

<p>All the orchestration options you&#8217;ve seen so far have required you to think about and manage the servers you&#8217;re

using, though a bit less with each step up the abstraction ladder. The idea behind <em>serverless</em> is to allow you to

focus entirely on your app code, without having to think about servers at all. There are of course still servers there,

but they are behind the scenes, and fully managed for you.</p>

</div>

<div class="paragraph">

<p>The original model referred to as "serverless" was <em>Functions as a Service (FaaS)</em>, which works as follows:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Create a <em>deployment package</em> which contains just the source code to run one function (rather than a whole app).</p>

</li>

<li>

<p>Upload the deployment package to your <em>serverless provider</em>, which is typically a cloud provider like AWS, GCP, or

Azure (although you can also use tools like <a href="https://knative.dev/docs/">Knative</a> to add support for serverless in your

on-prem Kubernetes cluster).</p>

</li>

<li>

<p>Configure the serverless provider to <em>trigger</em> your function in response to certain events: e.g., an HTTP request,

a file upload, a new message in a queue.</p>

</li>

<li>

<p>When the trigger goes off, the serverless provider executes your function, passing it information about the event

as an input, and, in some cases, taking the data the function returns as an output, and passing it on elsewhere (e.g.,

sending it as an HTTP response).</p>

</li>

<li>

<p>When you need to deploy an update, you create a new deployment package and upload it to the serverless provider, who

will use it to respond to all future triggers.</p>

</li>

</ul>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Key takeaway #4</div>

<div class="paragraph">

<p>Serverless orchestration is an immutable infrastructure approach where you deploy and manage functions without having

to think about servers at all.</p>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>There are a few key points that are easy to miss that make serverless with the FaaS model stand out from all the other

orchestration options:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1">You focus on your code, not on the hardware</dt>

<dd>

<p>The goal of serverless is that you don&#8217;t have to think about the

hardware at all. If your trigger goes off 1,000 times per second or once per year, it&#8217;s completely up to the

serverless provider to manage the servers, clusters, auto scaling, and auto healing that are necessary to handle that

load.</p>

</dd>

<dt class="hdlist1">You focus on your code, not the OS</dt>

<dd>

<p>The deployment package only includes your app code. Notably, it does <em>not</em>

include anything about the OS or other tooling. Running, securing, and updating the OS is completely handled by the

serverless provider.</p>

</dd>

<dt class="hdlist1">You get even more speed</dt>

<dd>

<p>Serverless deployments are even faster than containers: whereas you can expect the build

and deploy cycle to take 5-10 minutes with VMs and 1-5 minutes with containers, with serverless, it can take less

than a minute. This is because the deployment packages are often tiny, containing just a small amount of source code

for one function, and there are no servers or clusters to spin up, so deployments are <em>fast</em>.</p>

</dd>

<dt class="hdlist1">You get even more efficiency</dt>

<dd>

<p>Serverless can make even more efficient use of computing resources than containers:

instead of scheduling long-running apps, you schedule short-running functions, which you can move around the cluster

extremely quickly onto any server that has spare resources. That said, most of these benefits accrue to the

cloud providers, but they do pass some of those cost savings down to the end-user too, offering serverless at

incredibly low prices.<sup class="footnote">[<a id="_footnoteref_17" class="footnote" href="13-footnotes.html#_footnotedef_17" title="View footnote.">17</a>]</sup></p>

</dd>

<dt class="hdlist1">Pricing scales perfectly with usage</dt>

<dd>

<p>With server, VM, and container orchestration, you typically pay per hour

to rent whatever hardware you need, <em>even if that hardware is sitting completely idle</em>. With serverless, you pay

per invocation, so the pricing scales exactly with usage. If usage is high, you pay more, but if usage goes to zero,

most serverless providers can <em>scale to zero</em>, which means you pay nothing.</p>

</dd>

</dl>

</div>

<div class="paragraph">

<p>While FaaS has some major benefits, it also typically comes with a number of limitations: for example, there are

often limits on deployment package size, how long your functions can run for, disk usage, event payload size, response

payload size, maximum concurrency, lack of SSH access (for debugging), and so on. Also, serverless often struggles with

<em>cold starts</em>, where on the first run, or the first run after a period of idleness, the serverless provider needs

to download your deployment package and run it, which can take a few seconds: this is plenty fast for a deployment, but

for some use cases, such as responding to live HTTP requests, it can be unacceptably slow. FaaS in particular also

struggles with use cases that require long-running connections, such as database connection pools or WebSockets: there

are solutions, but they are typically considerably more complicated than using long-running connections with other

orchestration approaches.</p>

</div>

<div class="paragraph">

<p>The FaaS model of serverless first became prominent in 2015 with the release of

<a href="https://aws.amazon.com/lambda/">AWS Lambda</a>. It grew in popularity very quickly, and since then, other cloud providers

have released their own FaaS offerings, such as <a href="https://cloud.google.com/functions?hl=en">GCP Cloud Functions</a> and

<a href="https://azure.microsoft.com/en-us/solutions/serverless">Azure serverless</a>.</p>

</div>

<div class="paragraph">

<p>In fact, serverless has become so popular, that these days, the term is being applied not only to FaaS, but other

models, too:</p>

</div>

<div class="dlist">

<dl>

<dt class="hdlist1"><a href="https://cloud.google.com/appengine?hl=en"><strong>Google App Engine (GAE)</strong></a></dt>

<dd>

<p>Released in 2008, GAE predates AWS Lambda,

and is perhaps the first serverless offering (though I don&#8217;t believe the term serverless was used back then), as it

allowed you to deploy web apps without having to think about servers or clusters. However, this required that the

apps were written in very specific ways, with even more limitations than Lambda: e.g., specific languages,

frameworks, data stores, runtime limits, data access patterns, etc.</p>

</dd>

<dt class="hdlist1">Serverless containers</dt>

<dd>

<p>A number of cloud providers these days allow you to run containers without having to manage

the servers or clusters under the hood. For example, <a href="https://aws.amazon.com/fargate/">AWS Fargate</a> lets you use

Amazon EKS or Amazon ECS without having to run or manage any worker nodes

yourself. Combining containers with serverless helps work around some of the limitations of FaaS: e.g., you can

have long-running containers, which avoids issues with cold starts and long-running connections. However, this very

same feature also nullifies the scale-to-zero benefits of serverless. Also, containers give you greater

portability than serverless, as serverless depends on provider-specific deployment packages. However, containers

are typically larger and container orchestration tools tend to be slower, so you lose some of the speed benefits,

and containers include the OS and other tooling, so you have more maintenance work to do (that said, with

containers, the OS kernel is shared with the underlying host, which is managed for you by the serverless provider).</p>

</dd>

<dt class="hdlist1">Serverless databases</dt>

<dd>

<p>The term serverless is now being applied to databases too, such as

<a href="https://aws.amazon.com/rds/aurora/serverless/">Amazon Aurora Serverless</a>. In this case, the term serverless

typically implies two things. First, you can use these databases without having to worry about running or managing

the underlying servers, hard-drives, etc. Second, these databases can typically scale to zero when not in use, so you

don&#8217;t have to pay hourly to run a server when things are idle (however, you typically do still pay for data storage).</p>

</dd>

</dl>

</div>

<div class="sect3">

<h3 id="example_serverless">An example of serverless orchestration</h3>

<div class="paragraph">

<p>To get a feel for serverless, let&#8217;s try out what is arguably the most popular approach, which is AWS Lambda and FaaS.

First, you&#8217;re going to deploy a Lambda function that can respond with "Hello, World!", and second, you&#8217;ll deploy

API Gateway to trigger the Lambda function when HTTP requests come in.</p>

</div>

<div class="sect4">

<h4 id="_example_serverless_functions_with_aws_lambda">Example: serverless functions with AWS Lambda</h4>

<div class="paragraph">

<p>The blog post series&#8217;s sample code repo includes a module called <code>lambda</code> in the <em>ch3/tofu/modules/lambda</em> folder that

can deploy a serverless function using AWS Lambda. To use the <code>lambda</code> module, create a <em>live/lambda-sample</em> folder to

use as a root module:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ cd fundamentals-of-devops

$ mkdir -p ch3/tofu/live/lambda-sample

$ cd ch3/tofu/live/lambda-sample</pre>

</div>

</div>

<div class="paragraph">

<p>In the <em>lambda-sample</em> folder, create a file called <em>main.tf</em> with the contents shown in <a href="04.html#example_lambda_function">Example 59</a>:</p>

</div>

<div id="example_lambda_function" class="exampleblock">

<div class="title">Example 59. Configure the <code>lambda</code> module (<em>ch3/tofu/live/lambda-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">provider &quot;aws&quot; {

  region = &quot;us-east-2&quot;

}



module &quot;function&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/lambda&quot;



  name = &quot;lambda-sample&quot;         # <b class="conum">(1)</b>



  src_dir = &quot;${path.module}/src&quot; # <b class="conum">(2)</b>

  runtime = &quot;nodejs20.x&quot;         # <b class="conum">(3)</b>

  handler = &quot;index.handler&quot;      # <b class="conum">(4)</b>



  memory_size = 128              # <b class="conum">(5)</b>

  timeout     = 5                # <b class="conum">(6)</b>



  environment_variables = {      # <b class="conum">(7)</b>

    NODE_ENV = &quot;production&quot;

  }

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This code sets the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>name</code>: The name to use for the Lambda function and all other resources created by this module.</p>

</li>

<li>

<p><code>src_dir</code>: The directory which contains the code for the Lambda function. The <code>lambda</code> module will zip this folder

up into a deployment package. <a href="04.html#example_lambda_node_src">Example 60</a> shows the contents of this folder.</p>

</li>

<li>

<p><code>runtime</code>: The runtime used by this function. AWS Lambda supports runtimes such as Node.js, Python, Java, Ruby,

and .NET, as well as the ability to create custom runtimes for all other languages (see the

<a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html">Lambda runtimes documentation</a> for details).</p>

</li>

<li>

<p><code>handler</code>: The <em>handler</em> or entrypoint to call your function. The format is <code>&lt;FILE&gt;.&lt;FUNCTION&gt;</code>, where

<code>&lt;FILE&gt;</code> is the file in your deployment package and <code>&lt;FUNCTION&gt;</code> is the name of the function to call in that file.

Lambda will pass this function the event information. The preceding code sets the handler to the <code>handler</code> function

in <em>index.js</em>, which is shown in <a href="04.html#example_lambda_node_src">Example 60</a>.</p>

</li>

<li>

<p><code>memory_size</code>: The amount of memory to give the Lambda function. Adding more memory also proportionally increases

the amount of CPU available, as well as the cost to run the function.</p>

</li>

<li>

<p><code>timeout</code>: The maximum amount of time the Lambda function has to run. The timeout limit is 15 minutes.</p>

</li>

<li>

<p><code>environment_variables</code>: Environment variables to set for the function. The preceding code sets the <code>NODE_ENV</code>

environment variable to "production" to tell the Node.js app and all its dependencies to run in production mode.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>Create a folder in <em>lambda-sample/src</em>, and inside that folder, create a file called <em>index.js</em>, which defines the

handler, as shown in <a href="04.html#example_lambda_node_src">Example 60</a>:</p>

</div>

<div id="example_lambda_node_src" class="exampleblock">

<div class="title">Example 60. The handler code in index.js (<em>ch3/tofu/live/lambda-sample/src/index.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">exports.handler = (event, context, callback) =&gt; {

  callback(<span style="color:#069">null</span>, {<span style="color:#606">statusCode</span>: <span style="color:#00D">200</span>, <span style="color:#606">body</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Hello, World!</span><span style="color:#710">&quot;</span></span>});

};</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>As you can see, this is a function that takes the <code>event</code> object as input and then uses the <code>callback</code> to return

a response which is a 200 OK with the text "Hello, World!"</p>

</div>

<div class="paragraph">

<p>Deploy the <code>lambda-sample</code> module the usual way:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu init

$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p><code>apply</code> should complete in just a few seconds: Lambda is fast! To see if it worked, open the

<a href="https://console.aws.amazon.com/lambda/home">Lambda console</a> in your browser, click on the function called

"sample-app-lambda," and you should see your function and the handler code, as shown in <a href="04.html#lambda_console">Figure 26</a>:</p>

</div>

<div id="lambda_console" class="imageblock">

<div class="content">

<img src="images/ch3/lambda-console.png" alt="The Lambda console shows your newly created function">

</div>

<div class="title">Figure 26. The Lambda console shows your newly created function</div>

</div>

<div class="paragraph">

<p>Currently, the function has no triggers, so it doesn&#8217;t really do anything. You can manually trigger it by clicking the

blue Test button. The console will pop up a box where you can enter test data in JSON format to send to the function

as the <code>event</code> object; leave everything at its default value and and click the Invoke button. That should run your

function and show you log output that looks similar to <a href="04.html#lambda_test_event">Figure 27</a>:</p>

</div>

<div id="lambda_test_event" class="imageblock">

<div class="content">

<img src="images/ch3/lambda-console-test-event.png" alt="The output from manually triggering the Lambda function with a test event">

</div>

<div class="title">Figure 27. The output from manually triggering the Lambda function with a test event</div>

</div>

<div class="paragraph">

<p>As you can see, your function has run, and responded with the expected 200 OK and "Hello, World!"</p>

</div>

<div class="paragraph">

<p>Triggering Lambda functions manually is great for learning and testing, but in the real world, if you want to build a

serverless web app, you need to be able to have HTTP requests trigger your function, as described in the next section.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_triggering_lambda_functions_with_http_requests_using_api_gateway">Example: triggering Lambda functions with HTTP requests using API Gateway</h4>

<div class="paragraph">

<p>You can configure a <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html">variety of events to trigger

your Lambda function</a>: e.g., you can have AWS automatically run your Lambda function each time a file is uploaded to

Amazon&#8217;s Simple Storage Service (S3), or a new message is written to a queue in Amazon&#8217;s Simple Queue Service (SQS), or

each time you get a new email in Amazon&#8217;s Simple Email Service (SES). So Lambda is a great choice for building

event-driven systems and background processing jobs.</p>

</div>

<div class="paragraph">

<p>You can also configure AWS to trigger a Lambda function each time you receive an HTTP request in

<a href="https://aws.amazon.com/api-gateway/">API Gateway</a>, which is a managed service for creating APIs. You can use API Gateway

to expose an entrypoint for your apps, managing routing, authentication, throttling, and so on. You can also

use API Gateway to create serverless web apps.</p>

</div>

<div class="paragraph">

<p>The blog post series&#8217;s sample code repo includes a module called <code>api-gateway</code> in the <em>ch3/tofu/modules/api-gateway</em>

folder that can deploy an <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api.html">HTTP API Gateway</a>,

a version of API Gateway designed for simple HTTP APIs, that knows how to trigger a Lambda function.

<a href="04.html#example_lambda_api_gateway">Example 61</a> shows how to update the <code>lambda-sample</code> module to use the <code>api-gateway</code> module:</p>

</div>

<div id="example_lambda_api_gateway" class="exampleblock">

<div class="title">Example 61. Configure the <code>api-gateway</code> module to trigger the Lambda function (<em>ch3/tofu/live/lambda-sample/main.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">module &quot;gateway&quot; {

  source = &quot;github.com/brikis98/fundamentals-of-devops-code//ch3/tofu/modules/api-gateway&quot;



  name               = &quot;lambda-sample&quot;              # <b class="conum">(1)</b>

  function_arn       = module.function.function_arn # <b class="conum">(2)</b>

  api_gateway_routes = [&quot;GET /&quot;]                    # <b class="conum">(3)</b>

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This code sets the following parameters:</p>

</div>

<div class="colist arabic">

<ol>

<li>

<p><code>name</code>: The name to use for the API Gateway and all the other resources created by the module.</p>

</li>

<li>

<p><code>function-arn</code>: The ARN of the Lambda function the API Gateway should trigger when it gets HTTP requests.</p>

</li>

<li>

<p><code>api_gateway_routes</code>: The routes that should trigger the Lambda function. The preceding code configures

an HTTP <code>GET</code> to the <code>/</code> path to as the only route.</p>

</li>

</ol>

</div>

<div class="paragraph">

<p>You should also add an output variable in <em>outputs.tf</em>, as shown in <a href="04.html#example_lambda_outputs">Example 62</a>:</p>

</div>

<div id="example_lambda_outputs" class="exampleblock">

<div class="title">Example 62. The <code>lambda-sample</code> module&#8217;s outputs (<em>ch3/tofu/live/lambda-sample/outputs.tf</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="terraform">output &quot;api_endpoint&quot; {

  value = module.gateway.api_endpoint

}</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>This code will give you the API Gateway&#8217;s domain name as an output.</p>

</div>

<div class="paragraph">

<p>Deploy the updates:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p>When <code>apply</code> completes, you should see the <code>api_endpoint</code> output:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>Apply complete! Resources: 5 added, 0 changed, 0 destroyed.



Outputs:



api_endpoint = "https://iome6ldq7i.execute-api.us-east-2.amazonaws.com"</pre>

</div>

</div>

<div class="paragraph">

<p>Open this output in a web browser, and you should see "Hello, World!" API Gateway is now routing requests to your Lambda

function. As load goes up and down, AWS will automatically scale your Lambda functions up and down, and API Gateway

will automatically distribute traffic across these functions.</p>

</div>

</div>

<div class="sect4">

<h4 id="_example_rolling_out_updates_with_lambda">Example: rolling out updates with Lambda</h4>

<div class="paragraph">

<p>By default, AWS Lambda natively supports a nearly instantaneous deployment model: that is, if you upload a new

deployment package, all new requests will start executing the code in that deployment package more or less immediately.</p>

</div>

<div class="paragraph">

<p>For example, try updating <em>lambda-sample/src/index.js</em> to respond with "Fundamentals of DevOps!" rather than

"Hello, World!", as shown in <a href="04.html#example_lambda_js_code_response">Example 63</a>:</p>

</div>

<div id="example_lambda_js_code_response" class="exampleblock">

<div class="title">Example 63. Update the Lambda function response text (<em>ch3/tofu/live/lambda-sample/src/index.js</em>)</div>

<div class="content">

<div class="listingblock">

<div class="content">

<pre class="CodeRay highlight"><code data-lang="javascript">exports.handler = (event, context, callback) =&gt; {

  callback(<span style="color:#069">null</span>, {<span style="color:#606">statusCode</span>: <span style="color:#00D">200</span>, <span style="color:#606">body</span>: <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Fundamentals of DevOps!</span><span style="color:#710">&quot;</span></span>});

};</code></pre>

</div>

</div>

</div>

</div>

<div class="paragraph">

<p>Re-run <code>apply</code> to deploy these changes:</p>

</div>

<div class="listingblock">

<div class="content">

<pre>$ tofu apply</pre>

</div>

</div>

<div class="paragraph">

<p><code>apply</code> should complete in a few seconds, and if you retry the <code>api_endpoint</code> URL, you&#8217;ll see "Fundamentals of DevOps!"

right away. So again, deployments with Lambda are <em>fast</em>! In fact, AWS Lambda does effectively an instantanesous

switchover from the old to the new version, so it&#8217;s effectively a <em>blue-green deployment</em> (which you&#8217;ll learn more about

in <a href="06.html#how_to_set_up_ci_cd">Part 5</a>).</p>

</div>

<div class="admonitionblock tip">

<table>

<tr>

<td class="icon">

<div class="title">Tip</div>

</td>

<td class="content">

<div class="title">Get your hands dirty: other tools for serverless web apps</div>

<div class="paragraph">

<p>To avoid introducing too many new tools, this blog post uses OpenTofu to deploy Lambda functions, which

works great for functions used for background jobs and event processing, but for serverless web apps, where you use a

mix of Lambda functions and API Gateway, the OpenTofu code can get very verbose (especially the API Gateway parts).

Moreover, if you&#8217;re using OpenTofu to manage a serverless webapp, you have no easy way to run or test that webapp

(especially the API Gateway endpoints) locally.</p>

</div>

<div class="paragraph">

<p>If you&#8217;re going to be building serverless web apps for production use cases, try out one of the following tools instead,

as they are purpose-built for serverless web apps, keep the code more concise, and give you ways to test locally:</p>

</div>

<div class="ulist">

<ul>

<li>

<p><a href="https://www.serverless.com/">Serverless Framework</a></p>

</li>

<li>

<p><a href="https://aws.amazon.com/serverless/sam/">SAM</a></p>

</li>

</ul>

</div>

</td>

</tr>

</table>

</div>

<div class="paragraph">

<p>When you&#8217;re done experimenting with the serverless code, run <code>tofu destroy</code> to undeploy all your infrastructure. This

ensures that your account doesn&#8217;t start accumulating any unwanted charges.</p>

</div>

</div>

</div>

</div>

<div class="sect2">

<h2 id="comparison_orchestration_options">Comparison of orchestration options</h2>

<div class="paragraph">

<p>You&#8217;ve now seen the most common approaches to orchestration: server orchestration, VM orchestration, container

orchestration, and serverless orchestration. <a href="04.html#orchestration_core_problems_comparison">Table 2</a> shows how these orchestration

approaches compare in their ability to solve the core orchestration problems introduced in the beginning of the

blog post in <a href="04.html#introduction_to_orchestration">Section 3.1</a>:</p>

</div>

<div class="admonitionblock note">

<table>

<tr>

<td class="icon">

<div class="title">Note</div>

</td>

<td class="content">

<div class="title">Lossy compression</div>

<div class="paragraph">

<p>As there are dozens of different tools within each orchestration category, the tables in this section only try to show

what you should expect from the <em>typical</em> tools in each category. Think of these tables as compressed guides to the

strengths &amp; weaknesses of each category, but be aware that, in the effort to compress this information, some of the

variation within a category gets lost.</p>

</div>

</td>

</tr>

</table>

</div>

<table id="orchestration_core_problems_comparison" class="tableblock frame-all grid-all stretch">

<caption class="title">Table 2. How orchestration approaches compare in terms of the core orchestration problems</caption>

<colgroup>

<col style="width: 7.6923%;">

<col style="width: 23.0769%;">

<col style="width: 23.0769%;">

<col style="width: 23.0769%;">

<col style="width: 23.077%;">

</colgroup>

<thead>

<tr>

<th class="tableblock halign-left valign-top">Problem</th>

<th class="tableblock halign-left valign-top">Server orchestration</th>

<th class="tableblock halign-left valign-top">VM orchestration</th>

<th class="tableblock halign-left valign-top">Container orchestration</th>

<th class="tableblock halign-left valign-top">Serverless orchestration</th>

</tr>

</thead>

<tbody>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Deployment</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">Manually specify which servers should run which apps. Limited deployment strategies: e.g., Ansible rolling

deployments.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">Define a template and the orchestrator spins up servers from that template. Limited deployment

strategies: e.g., ASG instance refresh.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">Set up worker nodes, define a template, and the orchestrator schedules containers on the worker nodes. Multiple

deployment strategies: e.g., rolling, canary, blue-green.<sup class="footnote">[<a id="_footnoteref_18" class="footnote" href="13-footnotes.html#_footnotedef_18" title="View footnote.">18</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">Upload a deployment package and let the orchestration tool run it whenever it is triggered. Multiple deployment

strategies: e.g., blue-green, canary, traffic shifting.<sup class="footnote">[<a id="_footnoteref_19" class="footnote" href="13-footnotes.html#_footnotedef_19" title="View footnote.">19</a>]</sup></p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Scheduling</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Not supported</strong></span></p>

<p class="tableblock">There is no scheduler built-in.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">A scheduler decides which VMs run where. As an end-user, you see (and pay for) one VM per server.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">A scheduler decides which containers run where. As an end-user, you get to run multiple containers per server.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">A scheduler decides where to run your deployment package. As an end-user, you see (and pay for) functions, not servers.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Rollback</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Not supported</strong></span></p>

<p class="tableblock">Mutable infrastructure practices have side effects, so there&#8217;s no automatic "undo." You always fix forward.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">With immutable infrastructure, if you hit an error with the new version, you go back to the old version.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">With immutable infrastructure, if you hit an error with the new version, you go back to the old version.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">With immutable infrastructure, if you hit an error with the new version, you go back to the old version.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Auto scaling</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Not supported</strong></span></p>

<p class="tableblock">The number of servers is fixed, and only changes manually.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., AWS ASGs supports auto scaling servers based on

<a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/scaling-overview.html">metrics, schedules, and historical patterns</a>.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., Kubernetes supports auto scaling of both pods and nodes based on

<a href="https://kubernetes.io/docs/concepts/workloads/autoscaling/">metrics, schedules, and events</a>.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., AWS Lambda handles scaling for you, including scale to zero, without you having to think about it at

all.<sup class="footnote">[<a id="_footnoteref_20" class="footnote" href="13-footnotes.html#_footnotedef_20" title="View footnote.">20</a>]</sup></p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Auto healing</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Not supported</strong></span></p>

<p class="tableblock">You have to manually restore servers and use process supervisors.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., ASGs automatically replace instances that crash or fail ELB health checks.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., Kubernetes replaces nodes that crash or pods that fail any one of a variety of health

checks.<sup class="footnote">[<a id="_footnoteref_21" class="footnote" href="13-footnotes.html#_footnotedef_21" title="View footnote.">21</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., AWS Lambda handles auto healing of servers without you having to think about it at all.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Configuration</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Ansible has support for variables, roles, templates, inventories, etc.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., create an OpenTofu module that exposes variables to configure ASGs for different environments.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Kubernetes supports <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMaps</a>, which

give you a way to pass arbitrary key-value pairs to your apps.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Lambda functions can get configuration from

<a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html">environment

variables</a> and the

<a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ps-integration-lambda-extensions.html">SSM Parameter

Store</a>.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Secrets management</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock">E.g., use <a href="https://docs.ansible.com/ansible/latest/vault_guide/index.html">Ansible Vault</a> to encrypt and manage

sensitive data.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">You typically have to handle this yourself: e.g., have your app read from a secret store during boot.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Kubernetes supports <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Secrets</a> as a way to

pass sensitive data to your apps.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., AWS Lambda can

<a href="https://docs.aws.amazon.com/secretsmanager/latest/userguide/retrieving-secrets_lambda.html">automatically fetch

secrets from AWS Secrets Manager</a>.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Load balancing</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">E.g., Manually deploy Nginx.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Use AWS ASGs with ALBs.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., use Kubernetes Services with Kubernetes Deployments.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., use API Gateway to trigger Lambda functions in response to HTTP requests.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Service communication</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">E.g., have Ansible pass the IP addresses of servers in its inventory to your apps.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">E.g., you can use load balancers between ASGs, using AWS APIs to discovery load balancer URLs.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., use a Kubernetes Service to expose your app on a private IP within the cluster, and then discover IPs

using environment variables or DNS.<sup class="footnote">[<a id="_footnoteref_22" class="footnote" href="13-footnotes.html#_footnotedef_22" title="View footnote.">22</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Lambda functions can trigger other Lambda functions either directly via API calls or indirectly via

events.<sup class="footnote">[<a id="_footnoteref_23" class="footnote" href="13-footnotes.html#_footnotedef_23" title="View footnote.">23</a>]</sup></p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Disk management</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Manual</strong></span></p>

<p class="tableblock">Manually attach and manage hard drives.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Supported</strong></span></p>

<p class="tableblock"><em>Ephemeral</em> disks are typically supported, but <em>permanent disks</em> have to be managed manually.<sup class="footnote">[<a id="_footnoteref_24" class="footnote" href="13-footnotes.html#_footnotedef_24" title="View footnote.">24</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Strong support</strong></span></p>

<p class="tableblock">E.g., Kubernetes supports both <a href="https://kubernetes.io/docs/concepts/storage/volumes/">Volumes</a> and

<a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a>.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Not supported</strong></span></p>

<p class="tableblock">E.g., the file system for Lambda functions is read-only. If you need to store data, you must use an external data store.</p></td>

</tr>

</tbody>

</table>

<div class="paragraph">

<p>While the core orchestration problems define <em>what</em> an orchestration tool should do, it&#8217;s also important to consider

<em>how</em> they do it. As you used the various orchestration approaches in this blog post, you probably saw

that they varied across a number of other dimensions, such as speed, ease of learning, and so on.

<a href="04.html#orchestration_attributes_comparison">Table 3</a> shows how the different orchestration approaches compare across these

dimensions, which I&#8217;ll refer to as the <em>core orchestration attributes</em>:</p>

</div>

<table id="orchestration_attributes_comparison" class="tableblock frame-all grid-all stretch">

<caption class="title">Table 3. How orchestration approaches compare in terms of core orchestration attributes</caption>

<colgroup>

<col style="width: 7.6923%;">

<col style="width: 23.0769%;">

<col style="width: 23.0769%;">

<col style="width: 23.0769%;">

<col style="width: 23.077%;">

</colgroup>

<thead>

<tr>

<th class="tableblock halign-left valign-top">Dimension</th>

<th class="tableblock halign-left valign-top">Server orchestration</th>

<th class="tableblock halign-left valign-top">VM orchestration</th>

<th class="tableblock halign-left valign-top">Container orchestration</th>

<th class="tableblock halign-left valign-top">Serverless orchestration</th>

</tr>

</thead>

<tbody>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Deployment speed</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Moderate</strong></span></p>

<p class="tableblock">Simple code changes: 1-5 minutes. Major dependency or OS upgrades: 5-60 minutes.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Moderate</strong></span></p>

<p class="tableblock">Building a new VM image and rolling it out: 5-30 minutes.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">Building a new container image and rolling it out: 1-5 minutes.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Building a new deployment package and rolling it: 1 minute.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Maintenance</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">You have to maintain the servers, the OS and tools on each server, and the orchestration tool itself.<sup class="footnote">[<a id="_footnoteref_25" class="footnote" href="13-footnotes.html#_footnotedef_25" title="View footnote.">25</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Moderate</strong></span></p>

<p class="tableblock">You have to maintain the virtual servers and the OS and tools in each VM image.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">You have to maintain the control plane, worker nodes, the OS and tools in each Docker image, and the orchestration tool

itself.<sup class="footnote">[<a id="_footnoteref_26" class="footnote" href="13-footnotes.html#_footnotedef_26" title="View footnote.">26</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">There are no servers, no OS, and no orchestration tools to maintain.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Ease of learning</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">Most people understand this model quickly (a few days).</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">Most people understand this model quickly (a few days).</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">Most people understand containers quickly, but container orchestration tools, especially Kubernetes, take a long time

to learn (a few weeks).</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Most people understand this model very quickly (less than a day).</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Dev/prod parity</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">It&#8217;s rare to use a server orchestration tool (e.g., Ansible) in your local dev environment.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">You can&#8217;t run most VM orchestration tools (e.g., AWS ASG) in your local dev environment.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">It&#8217;s very common to run Docker containers in your local dev environment.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">It&#8217;s very common to run serverless apps in your local dev environment.<sup class="footnote">[<a id="_footnoteref_27" class="footnote" href="13-footnotes.html#_footnotedef_27" title="View footnote.">27</a>]</sup></p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Maturity</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">The oldest approach, with large, open source communities (e.g., Ansible, Chef, Puppet), so you get many person-years of

maturity.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Moderate</strong></span></p>

<p class="tableblock">The second-oldest approach, but mostly proprietary (e.g., AWS ASGs), so not as many person-years of maturity as the age

would suggest.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">A newer approach, but with massive, open source communities (especially Kubernetes), so you get many person-years of

maturity.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">The youngest approach, and mostly proprietary (e.g., AWS Lambda), so not mature at all.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Debugging</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">Full access to the servers and no extra layers of abstraction makes debugging easier, but mutable infrastructure

practices make debugging harder.<sup class="footnote">[<a id="_footnoteref_28" class="footnote" href="13-footnotes.html#_footnotedef_28" title="View footnote.">28</a>]</sup></p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Full access to the virtual servers, a simple abstraction layer, and immutable VM images all make debugging easier.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">Full access to the servers, sometimes full access to the containers<sup class="footnote">[<a id="_footnoteref_29" class="footnote" href="13-footnotes.html#_footnotedef_29" title="View footnote.">29</a>]</sup>, and immutable container images make debugging easier, but multiple layers of abstraction, and

the complexity of orchestration tools make debugging challenging.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">No access to the servers, and everything is abstracted away from you, which can make debugging very challenging.</p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Long-running tasks</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Typically, long-running tasks work fine.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Typically, long-running tasks work fine.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Typically, long-running tasks work fine.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">Limits on runtimes and numerous hoops to jump through for long-running connections.<sup class="footnote">[<a id="_footnoteref_30" class="footnote" href="13-footnotes.html#_footnotedef_30" title="View footnote.">30</a>]</sup></p></td>

</tr>

<tr>

<td class="tableblock halign-left valign-top"><p class="tableblock">Performance tuning</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="lime-background"><strong>Very strong</strong></span></p>

<p class="tableblock">Full control over the hardware.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="aqua-background"><strong>Strong</strong></span></p>

<p class="tableblock">Full control over the virtualized hardware. However, you may hit the <em>noisy neighbor</em> problem: other VMs

running on the same underlying physical server sometimes cause performance issues.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="yellow-background"><strong>Moderate</strong></span></p>

<p class="tableblock">The same trade-offs as VMs for worker nodes, plus the added layer of containers, which makes the noisy neighbor problem

and performance tuning more complicated.</p></td>

<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="red-background"><strong>Weak</strong></span></p>

<p class="tableblock">No control over the underlying hardware, plus the additional challenge of cold starts, so performance tuning is very

challenging.</p></td>

</tr>

</tbody>

</table>

<div class="paragraph">

<p>I hope that next time you need to deploy an app, you can use <a href="04.html#orchestration_core_problems_comparison">Table 2</a> and

<a href="04.html#orchestration_attributes_comparison">Table 3</a> to pick the right tool for the job.</p>

</div>

</div>

<div class="sect2">

<h2 id="_conclusion_3">Conclusion</h2>

<div class="paragraph">

<p>You now know how to run your apps in a way that more closely handles the demands of production, including using

multiple replicas to avoid having a single point of failure, deploying load balancers to distribute traffic across the

replicas, and using deployment strategies to roll out updates to your replicas without downtime. You&#8217;ve seen a number

of orchestration approaches for handling all of this, summarized via the 4 takeaways from this

Part:</p>

</div>

<div class="ulist">

<ul>

<li>

<p>Server orchestration is an older, mutable infrastructure approach where you have a fixed set of servers that you

maintain and update in place.</p>

</li>

<li>

<p>VM orchestration is an immutable infrastructure approach where you deploy and manage VM images across virtualized

servers.</p>

</li>

<li>

<p>Container orchestration is an immutable infrastructure approach where you deploy and manage container images across a

cluster of servers.</p>

</li>

<li>

<p>Serverless orchestration is an immutable infrastructure approach where you deploy and manage functions without having

to think about servers at all.</p>

</li>

</ul>

</div>

<div class="paragraph">

<p>As you worked your way through the first few parts of this blog post series, you wrote and executed a bunch

of code, including Node.js, Ansible, OpenTofu, Docker, YAML, and so on. So far, you&#8217;ve been working on all this code

alone, but in the real world, you&#8217;ll most likely need to work on code with a whole team of developers. How do you

collaborate on code as a team so you aren&#8217;t constantly overwriting each other&#8217;s changes? How do you

minimize bugs and outages? How do you package and deploy your changes on a regular basis? These questions are

the focus of the next blog post, <a href="05.html#how_to_version_build_test">Part 4</a>.</p>

</div>

</div>

</div>

</div>

</div>
<div id="footer">

<div id="footer-text">

Last updated 2024-05-20 14:12:46 -0400

</div>

</div>


    </div>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>

<script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>
<script>
  anchors.add();
</script>

</body>

</html>